{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# DataFrame manipulation libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Evaluation and processing libraries:\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Keras libraries:\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GRU\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Position</th>\n",
       "      <th>Week</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>PassingYards</th>\n",
       "      <th>PassingTouchdowns</th>\n",
       "      <th>PassingInterceptions</th>\n",
       "      <th>RushingYards</th>\n",
       "      <th>RushingTouchdowns</th>\n",
       "      <th>Receptions</th>\n",
       "      <th>ReceivingYards</th>\n",
       "      <th>ReceivingTouchdowns</th>\n",
       "      <th>FumblesLost</th>\n",
       "      <th>FantasyPoints</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>1</td>\n",
       "      <td>Carlos Hyde</td>\n",
       "      <td>SF</td>\n",
       "      <td>RB</td>\n",
       "      <td>1</td>\n",
       "      <td>MIN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.20</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>2</td>\n",
       "      <td>Tom Brady</td>\n",
       "      <td>NE</td>\n",
       "      <td>QB</td>\n",
       "      <td>1</td>\n",
       "      <td>PIT</td>\n",
       "      <td>288</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.62</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>3</td>\n",
       "      <td>Rob Gronkowski</td>\n",
       "      <td>NE</td>\n",
       "      <td>TE</td>\n",
       "      <td>1</td>\n",
       "      <td>PIT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.40</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>4</td>\n",
       "      <td>Julio Jones</td>\n",
       "      <td>ATL</td>\n",
       "      <td>WR</td>\n",
       "      <td>1</td>\n",
       "      <td>PHI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26.10</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>5</td>\n",
       "      <td>Carson Palmer</td>\n",
       "      <td>ARI</td>\n",
       "      <td>QB</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>307</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.68</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Rank            Name Team Position  Week Opponent  \\\n",
       "0  2015-09-13     1     Carlos Hyde   SF       RB     1      MIN   \n",
       "1  2015-09-13     2       Tom Brady   NE       QB     1      PIT   \n",
       "2  2015-09-13     3  Rob Gronkowski   NE       TE     1      PIT   \n",
       "3  2015-09-13     4     Julio Jones  ATL       WR     1      PHI   \n",
       "4  2015-09-13     5   Carson Palmer  ARI       QB     1       NO   \n",
       "\n",
       "   PassingYards  PassingTouchdowns  PassingInterceptions  RushingYards  \\\n",
       "0             0                  0                     0           168   \n",
       "1           288                  4                     0             1   \n",
       "2             0                  0                     0             0   \n",
       "3             0                  0                     0             0   \n",
       "4           307                  3                     0            14   \n",
       "\n",
       "   RushingTouchdowns  Receptions  ReceivingYards  ReceivingTouchdowns  \\\n",
       "0                  2           2              14                    0   \n",
       "1                  0           0               0                    0   \n",
       "2                  0           5              94                    3   \n",
       "3                  0           9             141                    2   \n",
       "4                  0           0               0                    0   \n",
       "\n",
       "   FumblesLost  FantasyPoints  Year  \n",
       "0            0          30.20  2015  \n",
       "1            0          27.62  2015  \n",
       "2            0          27.40  2015  \n",
       "3            0          26.10  2015  \n",
       "4            0          25.68  2015  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in CSV data of top player performance per week in the 2015, 2016, 2017, and 2018 NFL seasons:\n",
    "df = pd.read_csv('../../clean_data/weekly_player_performance_2015_to_2018.csv')\n",
    "df.head()  # preview first 5 rows of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                    datetime64[ns]\n",
       "Rank                             int64\n",
       "Name                            object\n",
       "Team                            object\n",
       "Position                        object\n",
       "Week                             int64\n",
       "Opponent                        object\n",
       "PassingYards                     int64\n",
       "PassingTouchdowns                int64\n",
       "PassingInterceptions             int64\n",
       "RushingYards                     int64\n",
       "RushingTouchdowns                int64\n",
       "Receptions                       int64\n",
       "ReceivingYards                   int64\n",
       "ReceivingTouchdowns              int64\n",
       "FumblesLost                      int64\n",
       "FantasyPoints                  float64\n",
       "Year                             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d') # Convert 'Date' feature into a Pandas datetime object\n",
    "df.dtypes  # examine data types of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Position</th>\n",
       "      <th>Week</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>PassingYards</th>\n",
       "      <th>PassingTouchdowns</th>\n",
       "      <th>PassingInterceptions</th>\n",
       "      <th>RushingYards</th>\n",
       "      <th>RushingTouchdowns</th>\n",
       "      <th>Receptions</th>\n",
       "      <th>ReceivingYards</th>\n",
       "      <th>ReceivingTouchdowns</th>\n",
       "      <th>FumblesLost</th>\n",
       "      <th>FantasyPoints</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-09-13</th>\n",
       "      <td>1</td>\n",
       "      <td>Carlos Hyde</td>\n",
       "      <td>SF</td>\n",
       "      <td>RB</td>\n",
       "      <td>1</td>\n",
       "      <td>MIN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.20</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-13</th>\n",
       "      <td>2</td>\n",
       "      <td>Tom Brady</td>\n",
       "      <td>NE</td>\n",
       "      <td>QB</td>\n",
       "      <td>1</td>\n",
       "      <td>PIT</td>\n",
       "      <td>288</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.62</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-13</th>\n",
       "      <td>3</td>\n",
       "      <td>Rob Gronkowski</td>\n",
       "      <td>NE</td>\n",
       "      <td>TE</td>\n",
       "      <td>1</td>\n",
       "      <td>PIT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.40</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-13</th>\n",
       "      <td>4</td>\n",
       "      <td>Julio Jones</td>\n",
       "      <td>ATL</td>\n",
       "      <td>WR</td>\n",
       "      <td>1</td>\n",
       "      <td>PHI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26.10</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-13</th>\n",
       "      <td>5</td>\n",
       "      <td>Carson Palmer</td>\n",
       "      <td>ARI</td>\n",
       "      <td>QB</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>307</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.68</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rank            Name Team Position  Week Opponent  PassingYards  \\\n",
       "Date                                                                          \n",
       "2015-09-13     1     Carlos Hyde   SF       RB     1      MIN             0   \n",
       "2015-09-13     2       Tom Brady   NE       QB     1      PIT           288   \n",
       "2015-09-13     3  Rob Gronkowski   NE       TE     1      PIT             0   \n",
       "2015-09-13     4     Julio Jones  ATL       WR     1      PHI             0   \n",
       "2015-09-13     5   Carson Palmer  ARI       QB     1       NO           307   \n",
       "\n",
       "            PassingTouchdowns  PassingInterceptions  RushingYards  \\\n",
       "Date                                                                \n",
       "2015-09-13                  0                     0           168   \n",
       "2015-09-13                  4                     0             1   \n",
       "2015-09-13                  0                     0             0   \n",
       "2015-09-13                  0                     0             0   \n",
       "2015-09-13                  3                     0            14   \n",
       "\n",
       "            RushingTouchdowns  Receptions  ReceivingYards  \\\n",
       "Date                                                        \n",
       "2015-09-13                  2           2              14   \n",
       "2015-09-13                  0           0               0   \n",
       "2015-09-13                  0           5              94   \n",
       "2015-09-13                  0           9             141   \n",
       "2015-09-13                  0           0               0   \n",
       "\n",
       "            ReceivingTouchdowns  FumblesLost  FantasyPoints  Year  \n",
       "Date                                                               \n",
       "2015-09-13                    0            0          30.20  2015  \n",
       "2015-09-13                    0            0          27.62  2015  \n",
       "2015-09-13                    3            0          27.40  2015  \n",
       "2015-09-13                    2            0          26.10  2015  \n",
       "2015-09-13                    0            0          25.68  2015  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('Date', inplace=True)  # set Date as the index\n",
    "df.sort_index(inplace=True)         # sort the dataframe by the Date index\n",
    "df.head()                           # examine first 5 rows to verify changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20400, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape  # preview dataframe dimensions; 20,400 rows and 17 columns as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert player's team, opponent, and position into one-hot encoded variables to use for FFNN:\n",
    "df_with_dummies = pd.get_dummies(df, columns=['Team', 'Opponent', 'Position'], drop_first=False)\n",
    "\n",
    "# Select feature variables to convert into floats; prevents errors when scaling data with StandardScaler:\n",
    "features = [col for col in df_with_dummies.columns if col not in ['Name', 'Week']]\n",
    "df_with_dummies[features] = df_with_dummies[features].astype(float)\n",
    "\n",
    "# Assign X as features to be used for predicting weekly fantasy points per player:\n",
    "X = df_with_dummies[[col for col in df_with_dummies.columns if col != 'FantasyPoints']]\n",
    "# Assign target vector y as weekly fantasy points per player:\n",
    "y = df_with_dummies['FantasyPoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rank                    float64\n",
       "Name                     object\n",
       "Week                      int64\n",
       "PassingYards            float64\n",
       "PassingTouchdowns       float64\n",
       "PassingInterceptions    float64\n",
       "RushingYards            float64\n",
       "RushingTouchdowns       float64\n",
       "Receptions              float64\n",
       "ReceivingYards          float64\n",
       "ReceivingTouchdowns     float64\n",
       "FumblesLost             float64\n",
       "Year                    float64\n",
       "Team_ARI                float64\n",
       "Team_ATL                float64\n",
       "Team_BAL                float64\n",
       "Team_BUF                float64\n",
       "Team_CAR                float64\n",
       "Team_CHI                float64\n",
       "Team_CIN                float64\n",
       "Team_CLE                float64\n",
       "Team_DAL                float64\n",
       "Team_DEN                float64\n",
       "Team_DET                float64\n",
       "Team_GB                 float64\n",
       "Team_HOU                float64\n",
       "Team_IND                float64\n",
       "Team_JAX                float64\n",
       "Team_KC                 float64\n",
       "Team_LAC                float64\n",
       "                         ...   \n",
       "Opponent_CLE            float64\n",
       "Opponent_DAL            float64\n",
       "Opponent_DEN            float64\n",
       "Opponent_DET            float64\n",
       "Opponent_GB             float64\n",
       "Opponent_HOU            float64\n",
       "Opponent_IND            float64\n",
       "Opponent_JAX            float64\n",
       "Opponent_KC             float64\n",
       "Opponent_LAC            float64\n",
       "Opponent_LAR            float64\n",
       "Opponent_MIA            float64\n",
       "Opponent_MIN            float64\n",
       "Opponent_NE             float64\n",
       "Opponent_NO             float64\n",
       "Opponent_NYG            float64\n",
       "Opponent_NYJ            float64\n",
       "Opponent_OAK            float64\n",
       "Opponent_PHI            float64\n",
       "Opponent_PIT            float64\n",
       "Opponent_SEA            float64\n",
       "Opponent_SF             float64\n",
       "Opponent_TB             float64\n",
       "Opponent_TEN            float64\n",
       "Opponent_WAS            float64\n",
       "Position_FB             float64\n",
       "Position_QB             float64\n",
       "Position_RB             float64\n",
       "Position_TE             float64\n",
       "Position_WR             float64\n",
       "Length: 82, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes  # verify that data types have been properly cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y data into a training set and validation set:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all columns to use as predictive features using StandardScaler:\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train.drop(columns = ['Name', 'Week']))\n",
    "X_test_sc = ss.transform(X_test.drop(columns = ['Name', 'Week']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40830156, -0.32569876, -0.26948036, -0.21607813,  0.32653258,\n",
       "        -0.25192244, -0.51896593, -0.4531034 , -0.38336799, -0.20342918,\n",
       "        -1.34067133, -0.17684817, -0.18644735, -0.18700964, -0.18794355,\n",
       "        -0.17860924, -0.17487318, -0.17207467, -0.17684817, -0.17606051,\n",
       "        -0.18093394, -0.17724085, -0.17625772, -0.18112649, -0.17546773,\n",
       "        -0.17880398, -0.17625772, -0.17684817,  5.87357131, -0.17880398,\n",
       "        -0.17958107, -0.18663494, -0.18151105, -0.17977488, -0.17507156,\n",
       "        -0.18757046, -0.18304223, -0.17996851, -0.18112649, -0.18246935,\n",
       "        -0.1818949 , -0.18074121, -0.17782843, -0.1818949 , -0.18437293,\n",
       "        -0.18151105, -0.18380366, -0.17938707, -0.17841432,  5.4976804 ,\n",
       "        -0.18285144, -0.18285144, -0.17327891, -0.18112649, -0.17821921,\n",
       "        -0.17821921, -0.18361356, -0.17821921, -0.17899853, -0.17919289,\n",
       "        -0.17880398, -0.18112649, -0.17841432, -0.18074121, -0.17782843,\n",
       "        -0.17802392, -0.18456235, -0.18035522, -0.17802392, -0.17763276,\n",
       "        -0.17066021, -0.17625772, -0.17958107, -0.18035522, -0.17645473,\n",
       "        -0.17724085, -0.36399787,  1.68791487, -0.5021437 , -0.80189852],\n",
       "       [-0.70924942, -0.32569876, -0.26948036, -0.21607813,  2.73555666,\n",
       "        -0.25192244, -0.09110847, -0.3581574 , -0.38336799, -0.20342918,\n",
       "        -0.4468515 , -0.17684817, -0.18644735, -0.18700964, -0.18794355,\n",
       "        -0.17860924, -0.17487318, -0.17207467, -0.17684817, -0.17606051,\n",
       "        -0.18093394, -0.17724085, -0.17625772, -0.18112649, -0.17546773,\n",
       "        -0.17880398, -0.17625772, -0.17684817, -0.17025417, -0.17880398,\n",
       "        -0.17958107, -0.18663494,  5.50930658, -0.17977488, -0.17507156,\n",
       "        -0.18757046, -0.18304223, -0.17996851, -0.18112649, -0.18246935,\n",
       "        -0.1818949 , -0.18074121, -0.17782843,  5.4976804 , -0.18437293,\n",
       "        -0.18151105, -0.18380366, -0.17938707, -0.17841432, -0.1818949 ,\n",
       "        -0.18285144, -0.18285144, -0.17327891, -0.18112649, -0.17821921,\n",
       "        -0.17821921, -0.18361356, -0.17821921, -0.17899853, -0.17919289,\n",
       "        -0.17880398, -0.18112649, -0.17841432, -0.18074121, -0.17782843,\n",
       "        -0.17802392, -0.18456235, -0.18035522, -0.17802392, -0.17763276,\n",
       "        -0.17066021, -0.17625772, -0.17958107, -0.18035522, -0.17645473,\n",
       "        -0.17724085, -0.36399787,  1.68791487, -0.5021437 , -0.80189852],\n",
       "       [-0.9255496 , -0.32569876, -0.26948036, -0.21607813, -0.44925484,\n",
       "        -0.25192244,  1.19246392,  0.90778923,  2.06060297, -0.20342918,\n",
       "        -1.34067133, -0.17684817, -0.18644735, -0.18700964, -0.18794355,\n",
       "        -0.17860924, -0.17487318, -0.17207467, -0.17684817, -0.17606051,\n",
       "        -0.18093394, -0.17724085, -0.17625772, -0.18112649, -0.17546773,\n",
       "        -0.17880398, -0.17625772, -0.17684817, -0.17025417, -0.17880398,\n",
       "        -0.17958107,  5.35805355, -0.18151105, -0.17977488, -0.17507156,\n",
       "        -0.18757046, -0.18304223, -0.17996851, -0.18112649, -0.18246935,\n",
       "        -0.1818949 , -0.18074121, -0.17782843, -0.1818949 , -0.18437293,\n",
       "        -0.18151105, -0.18380366, -0.17938707, -0.17841432, -0.1818949 ,\n",
       "        -0.18285144, -0.18285144, -0.17327891, -0.18112649, -0.17821921,\n",
       "        -0.17821921, -0.18361356, -0.17821921, -0.17899853, -0.17919289,\n",
       "        -0.17880398, -0.18112649, -0.17841432, -0.18074121, -0.17782843,\n",
       "        -0.17802392, -0.18456235, -0.18035522, -0.17802392, -0.17763276,\n",
       "        -0.17066021, -0.17625772, -0.17958107,  5.54461348, -0.17645473,\n",
       "        -0.17724085, -0.36399787, -0.59244694,  1.99146181, -0.80189852],\n",
       "       [-1.33411663, -0.32569876, -0.26948036, -0.21607813, -0.44925484,\n",
       "        -0.25192244,  1.62032138,  2.17373587,  2.06060297, -0.20342918,\n",
       "         1.34078817, -0.17684817, -0.18644735, -0.18700964, -0.18794355,\n",
       "        -0.17860924, -0.17487318, -0.17207467, -0.17684817,  5.67986528,\n",
       "        -0.18093394, -0.17724085, -0.17625772, -0.18112649, -0.17546773,\n",
       "        -0.17880398, -0.17625772, -0.17684817, -0.17025417, -0.17880398,\n",
       "        -0.17958107, -0.18663494, -0.18151105, -0.17977488, -0.17507156,\n",
       "        -0.18757046, -0.18304223, -0.17996851, -0.18112649, -0.18246935,\n",
       "        -0.1818949 , -0.18074121, -0.17782843, -0.1818949 , -0.18437293,\n",
       "        -0.18151105, -0.18380366, -0.17938707, -0.17841432, -0.1818949 ,\n",
       "        -0.18285144, -0.18285144, -0.17327891, -0.18112649, -0.17821921,\n",
       "        -0.17821921, -0.18361356, -0.17821921, -0.17899853, -0.17919289,\n",
       "        -0.17880398, -0.18112649, -0.17841432, -0.18074121, -0.17782843,\n",
       "         5.61722276, -0.18456235, -0.18035522, -0.17802392, -0.17763276,\n",
       "        -0.17066021, -0.17625772, -0.17958107, -0.18035522, -0.17645473,\n",
       "        -0.17724085, -0.36399787, -0.59244694, -0.5021437 ,  1.24704058],\n",
       "       [ 0.50443497, -0.32569876, -0.26948036, -0.21607813, -0.04094567,\n",
       "        -0.25192244, -0.51896593, -0.42145473, -0.38336799, -0.20342918,\n",
       "         1.34078817, -0.17684817, -0.18644735, -0.18700964, -0.18794355,\n",
       "        -0.17860924, -0.17487318,  5.81143074, -0.17684817, -0.17606051,\n",
       "        -0.18093394, -0.17724085, -0.17625772, -0.18112649, -0.17546773,\n",
       "        -0.17880398, -0.17625772, -0.17684817, -0.17025417, -0.17880398,\n",
       "        -0.17958107, -0.18663494, -0.18151105, -0.17977488, -0.17507156,\n",
       "        -0.18757046, -0.18304223, -0.17996851, -0.18112649, -0.18246935,\n",
       "        -0.1818949 , -0.18074121, -0.17782843, -0.1818949 , -0.18437293,\n",
       "        -0.18151105, -0.18380366, -0.17938707, -0.17841432, -0.1818949 ,\n",
       "         5.46892045, -0.18285144, -0.17327891, -0.18112649, -0.17821921,\n",
       "        -0.17821921, -0.18361356, -0.17821921, -0.17899853, -0.17919289,\n",
       "        -0.17880398, -0.18112649, -0.17841432, -0.18074121, -0.17782843,\n",
       "        -0.17802392, -0.18456235, -0.18035522, -0.17802392, -0.17763276,\n",
       "        -0.17066021, -0.17625772, -0.17958107, -0.18035522, -0.17645473,\n",
       "        -0.17724085, -0.36399787,  1.68791487, -0.5021437 , -0.80189852]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sc[0:5]  # preview first 5 scaled X values in the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5100, 80)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sc.shape  # check shape of scaled X validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and build feed-forward neural network to predict player performance per week:\n",
    "model = Sequential()                                        # instantiate model\n",
    "model.add(Dense(80, activation='relu', input_shape=(80,)))  # input layer with 80 neurons\n",
    "model.add(Dense(40, activation='relu'))                     # first hidden layer with 40 neurons\n",
    "model.add(Dense(20, activation='relu'))                     # second hidden layer with 20 neurons\n",
    "model.add(Dense(10, activation='relu'))                     # third hidden layer with 10 neurons\n",
    "model.add(Dense(5, activation='relu'))                      # fourth hidden layer with 5 neurons\n",
    "model.add(Dense(1))                                         # output layer with 1 neuron; represents predicted points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the FFNN model:\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "# loss function = mean squared error\n",
    "# optimization function = adam\n",
    "# evaluation metric = mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 15300 samples, validate on 5100 samples\n",
      "Epoch 1/120\n",
      "15300/15300 [==============================] - 1s 38us/step - loss: 91.1134 - mean_absolute_error: 6.5262 - val_loss: 86.0854 - val_mean_absolute_error: 6.2096\n",
      "Epoch 2/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 61.0107 - mean_absolute_error: 5.2139 - val_loss: 20.1474 - val_mean_absolute_error: 3.9023\n",
      "Epoch 3/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 7.5785 - mean_absolute_error: 2.1829 - val_loss: 2.2807 - val_mean_absolute_error: 1.2090\n",
      "Epoch 4/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 1.3336 - mean_absolute_error: 0.8938 - val_loss: 0.9014 - val_mean_absolute_error: 0.7272\n",
      "Epoch 5/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.6737 - mean_absolute_error: 0.6326 - val_loss: 0.5880 - val_mean_absolute_error: 0.5822\n",
      "Epoch 6/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.4508 - mean_absolute_error: 0.5154 - val_loss: 0.4341 - val_mean_absolute_error: 0.4949\n",
      "Epoch 7/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.3293 - mean_absolute_error: 0.4347 - val_loss: 0.3404 - val_mean_absolute_error: 0.4315\n",
      "Epoch 8/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.2612 - mean_absolute_error: 0.3839 - val_loss: 0.2916 - val_mean_absolute_error: 0.3938\n",
      "Epoch 9/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.2245 - mean_absolute_error: 0.3513 - val_loss: 0.2610 - val_mean_absolute_error: 0.3676\n",
      "Epoch 10/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.2013 - mean_absolute_error: 0.3302 - val_loss: 0.2443 - val_mean_absolute_error: 0.3530\n",
      "Epoch 11/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.1856 - mean_absolute_error: 0.3146 - val_loss: 0.2302 - val_mean_absolute_error: 0.3378\n",
      "Epoch 12/120\n",
      "15300/15300 [==============================] - 0s 17us/step - loss: 0.1736 - mean_absolute_error: 0.3022 - val_loss: 0.2223 - val_mean_absolute_error: 0.3334\n",
      "Epoch 13/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.1640 - mean_absolute_error: 0.2931 - val_loss: 0.2147 - val_mean_absolute_error: 0.3225\n",
      "Epoch 14/120\n",
      "15300/15300 [==============================] - 0s 23us/step - loss: 0.1559 - mean_absolute_error: 0.2832 - val_loss: 0.2097 - val_mean_absolute_error: 0.3168\n",
      "Epoch 15/120\n",
      "15300/15300 [==============================] - 0s 20us/step - loss: 0.1488 - mean_absolute_error: 0.2753 - val_loss: 0.2049 - val_mean_absolute_error: 0.3140\n",
      "Epoch 16/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.1438 - mean_absolute_error: 0.2703 - val_loss: 0.1982 - val_mean_absolute_error: 0.3059\n",
      "Epoch 17/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.1384 - mean_absolute_error: 0.2638 - val_loss: 0.1953 - val_mean_absolute_error: 0.3005\n",
      "Epoch 18/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.1347 - mean_absolute_error: 0.2591 - val_loss: 0.1950 - val_mean_absolute_error: 0.2970\n",
      "Epoch 19/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.1305 - mean_absolute_error: 0.2529 - val_loss: 0.1869 - val_mean_absolute_error: 0.2920\n",
      "Epoch 20/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.1253 - mean_absolute_error: 0.2484 - val_loss: 0.1855 - val_mean_absolute_error: 0.2868\n",
      "Epoch 21/120\n",
      "15300/15300 [==============================] - 0s 17us/step - loss: 0.1224 - mean_absolute_error: 0.2440 - val_loss: 0.1836 - val_mean_absolute_error: 0.2877\n",
      "Epoch 22/120\n",
      "15300/15300 [==============================] - 0s 20us/step - loss: 0.1204 - mean_absolute_error: 0.2417 - val_loss: 0.1814 - val_mean_absolute_error: 0.2831\n",
      "Epoch 23/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.1154 - mean_absolute_error: 0.2358 - val_loss: 0.1764 - val_mean_absolute_error: 0.2785\n",
      "Epoch 24/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.1128 - mean_absolute_error: 0.2313 - val_loss: 0.1760 - val_mean_absolute_error: 0.2786\n",
      "Epoch 25/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.1103 - mean_absolute_error: 0.2286 - val_loss: 0.1757 - val_mean_absolute_error: 0.2774\n",
      "Epoch 26/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.1081 - mean_absolute_error: 0.2255 - val_loss: 0.1726 - val_mean_absolute_error: 0.2721\n",
      "Epoch 27/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.1068 - mean_absolute_error: 0.2228 - val_loss: 0.1700 - val_mean_absolute_error: 0.2706\n",
      "Epoch 28/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.1036 - mean_absolute_error: 0.2194 - val_loss: 0.1711 - val_mean_absolute_error: 0.2651\n",
      "Epoch 29/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.1033 - mean_absolute_error: 0.2182 - val_loss: 0.1677 - val_mean_absolute_error: 0.2640\n",
      "Epoch 30/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.1010 - mean_absolute_error: 0.2157 - val_loss: 0.1670 - val_mean_absolute_error: 0.2646\n",
      "Epoch 31/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0987 - mean_absolute_error: 0.2120 - val_loss: 0.1660 - val_mean_absolute_error: 0.2613\n",
      "Epoch 32/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0972 - mean_absolute_error: 0.2097 - val_loss: 0.1646 - val_mean_absolute_error: 0.2606\n",
      "Epoch 33/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0958 - mean_absolute_error: 0.2072 - val_loss: 0.1623 - val_mean_absolute_error: 0.2552\n",
      "Epoch 34/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0941 - mean_absolute_error: 0.2048 - val_loss: 0.1629 - val_mean_absolute_error: 0.2570\n",
      "Epoch 35/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0933 - mean_absolute_error: 0.2049 - val_loss: 0.1623 - val_mean_absolute_error: 0.2556\n",
      "Epoch 36/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0925 - mean_absolute_error: 0.2027 - val_loss: 0.1592 - val_mean_absolute_error: 0.2511\n",
      "Epoch 37/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0908 - mean_absolute_error: 0.2005 - val_loss: 0.1594 - val_mean_absolute_error: 0.2515\n",
      "Epoch 38/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0893 - mean_absolute_error: 0.1984 - val_loss: 0.1581 - val_mean_absolute_error: 0.2493\n",
      "Epoch 39/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0884 - mean_absolute_error: 0.1966 - val_loss: 0.1569 - val_mean_absolute_error: 0.2474\n",
      "Epoch 40/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0880 - mean_absolute_error: 0.1956 - val_loss: 0.1603 - val_mean_absolute_error: 0.2484\n",
      "Epoch 41/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0858 - mean_absolute_error: 0.1930 - val_loss: 0.1547 - val_mean_absolute_error: 0.2442\n",
      "Epoch 42/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0852 - mean_absolute_error: 0.1911 - val_loss: 0.1572 - val_mean_absolute_error: 0.2431\n",
      "Epoch 43/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0866 - mean_absolute_error: 0.1930 - val_loss: 0.1535 - val_mean_absolute_error: 0.2430\n",
      "Epoch 44/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0848 - mean_absolute_error: 0.1907 - val_loss: 0.1533 - val_mean_absolute_error: 0.2412\n",
      "Epoch 45/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0838 - mean_absolute_error: 0.1886 - val_loss: 0.1569 - val_mean_absolute_error: 0.2468\n",
      "Epoch 46/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0817 - mean_absolute_error: 0.1863 - val_loss: 0.1518 - val_mean_absolute_error: 0.2377\n",
      "Epoch 47/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0808 - mean_absolute_error: 0.1842 - val_loss: 0.1524 - val_mean_absolute_error: 0.2356\n",
      "Epoch 48/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0836 - mean_absolute_error: 0.1867 - val_loss: 0.1633 - val_mean_absolute_error: 0.2584\n",
      "Epoch 49/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0828 - mean_absolute_error: 0.1870 - val_loss: 0.1554 - val_mean_absolute_error: 0.2436\n",
      "Epoch 50/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0778 - mean_absolute_error: 0.1799 - val_loss: 0.1527 - val_mean_absolute_error: 0.2359\n",
      "Epoch 51/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0788 - mean_absolute_error: 0.1805 - val_loss: 0.1535 - val_mean_absolute_error: 0.2399\n",
      "Epoch 52/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0777 - mean_absolute_error: 0.1793 - val_loss: 0.1546 - val_mean_absolute_error: 0.2407\n",
      "Epoch 53/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0775 - mean_absolute_error: 0.1787 - val_loss: 0.1517 - val_mean_absolute_error: 0.2349\n",
      "Epoch 54/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0774 - mean_absolute_error: 0.1792 - val_loss: 0.1487 - val_mean_absolute_error: 0.2320\n",
      "Epoch 55/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0746 - mean_absolute_error: 0.1741 - val_loss: 0.1534 - val_mean_absolute_error: 0.2378\n",
      "Epoch 56/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0739 - mean_absolute_error: 0.1725 - val_loss: 0.1527 - val_mean_absolute_error: 0.2380\n",
      "Epoch 57/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0746 - mean_absolute_error: 0.1731 - val_loss: 0.1510 - val_mean_absolute_error: 0.2318\n",
      "Epoch 58/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0740 - mean_absolute_error: 0.1739 - val_loss: 0.1548 - val_mean_absolute_error: 0.2382\n",
      "Epoch 59/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0747 - mean_absolute_error: 0.1732 - val_loss: 0.1478 - val_mean_absolute_error: 0.2270\n",
      "Epoch 60/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0712 - mean_absolute_error: 0.1691 - val_loss: 0.1486 - val_mean_absolute_error: 0.2277\n",
      "Epoch 61/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0700 - mean_absolute_error: 0.1667 - val_loss: 0.1504 - val_mean_absolute_error: 0.2316\n",
      "Epoch 62/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0737 - mean_absolute_error: 0.1720 - val_loss: 0.1566 - val_mean_absolute_error: 0.2326\n",
      "Epoch 63/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0711 - mean_absolute_error: 0.1679 - val_loss: 0.1456 - val_mean_absolute_error: 0.2222\n",
      "Epoch 64/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0713 - mean_absolute_error: 0.1698 - val_loss: 0.1474 - val_mean_absolute_error: 0.2231\n",
      "Epoch 65/120\n",
      "15300/15300 [==============================] - 0s 17us/step - loss: 0.0686 - mean_absolute_error: 0.1647 - val_loss: 0.1489 - val_mean_absolute_error: 0.2237\n",
      "Epoch 66/120\n",
      "15300/15300 [==============================] - 0s 17us/step - loss: 0.0693 - mean_absolute_error: 0.1651 - val_loss: 0.1516 - val_mean_absolute_error: 0.2336\n",
      "Epoch 67/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0670 - mean_absolute_error: 0.1618 - val_loss: 0.1488 - val_mean_absolute_error: 0.2265\n",
      "Epoch 68/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0666 - mean_absolute_error: 0.1627 - val_loss: 0.1526 - val_mean_absolute_error: 0.2344\n",
      "Epoch 69/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0669 - mean_absolute_error: 0.1625 - val_loss: 0.1489 - val_mean_absolute_error: 0.2264\n",
      "Epoch 70/120\n",
      "15300/15300 [==============================] - 0s 21us/step - loss: 0.0680 - mean_absolute_error: 0.1645 - val_loss: 0.1509 - val_mean_absolute_error: 0.2282\n",
      "Epoch 71/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.0654 - mean_absolute_error: 0.1598 - val_loss: 0.1457 - val_mean_absolute_error: 0.2209\n",
      "Epoch 72/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.0662 - mean_absolute_error: 0.1619 - val_loss: 0.1505 - val_mean_absolute_error: 0.2216\n",
      "Epoch 73/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0656 - mean_absolute_error: 0.1603 - val_loss: 0.1469 - val_mean_absolute_error: 0.2188\n",
      "Epoch 74/120\n",
      "15300/15300 [==============================] - 0s 17us/step - loss: 0.0653 - mean_absolute_error: 0.1591 - val_loss: 0.1472 - val_mean_absolute_error: 0.2231\n",
      "Epoch 75/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.0640 - mean_absolute_error: 0.1579 - val_loss: 0.1458 - val_mean_absolute_error: 0.2209\n",
      "Epoch 76/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0668 - mean_absolute_error: 0.1626 - val_loss: 0.1490 - val_mean_absolute_error: 0.2194\n",
      "Epoch 77/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0636 - mean_absolute_error: 0.1575 - val_loss: 0.1489 - val_mean_absolute_error: 0.2294\n",
      "Epoch 78/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0647 - mean_absolute_error: 0.1585 - val_loss: 0.1502 - val_mean_absolute_error: 0.2275\n",
      "Epoch 79/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0634 - mean_absolute_error: 0.1567 - val_loss: 0.1592 - val_mean_absolute_error: 0.2424\n",
      "Epoch 80/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0636 - mean_absolute_error: 0.1578 - val_loss: 0.1487 - val_mean_absolute_error: 0.2229\n",
      "Epoch 81/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0621 - mean_absolute_error: 0.1552 - val_loss: 0.1422 - val_mean_absolute_error: 0.2180\n",
      "Epoch 82/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0606 - mean_absolute_error: 0.1534 - val_loss: 0.1427 - val_mean_absolute_error: 0.2163\n",
      "Epoch 83/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0617 - mean_absolute_error: 0.1549 - val_loss: 0.1448 - val_mean_absolute_error: 0.2129\n",
      "Epoch 84/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0617 - mean_absolute_error: 0.1546 - val_loss: 0.1442 - val_mean_absolute_error: 0.2171\n",
      "Epoch 85/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0656 - mean_absolute_error: 0.1629 - val_loss: 0.1441 - val_mean_absolute_error: 0.2135\n",
      "Epoch 86/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.0626 - mean_absolute_error: 0.1568 - val_loss: 0.1527 - val_mean_absolute_error: 0.2320\n",
      "Epoch 87/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0649 - mean_absolute_error: 0.1614 - val_loss: 0.1443 - val_mean_absolute_error: 0.2156\n",
      "Epoch 88/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0604 - mean_absolute_error: 0.1536 - val_loss: 0.1459 - val_mean_absolute_error: 0.2234\n",
      "Epoch 89/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0586 - mean_absolute_error: 0.1506 - val_loss: 0.1446 - val_mean_absolute_error: 0.2191\n",
      "Epoch 90/120\n",
      "15300/15300 [==============================] - ETA: 0s - loss: 0.0572 - mean_absolute_error: 0.149 - 0s 17us/step - loss: 0.0578 - mean_absolute_error: 0.1497 - val_loss: 0.1469 - val_mean_absolute_error: 0.2241\n",
      "Epoch 91/120\n",
      "15300/15300 [==============================] - 0s 18us/step - loss: 0.0607 - mean_absolute_error: 0.1543 - val_loss: 0.1446 - val_mean_absolute_error: 0.2169\n",
      "Epoch 92/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0586 - mean_absolute_error: 0.1517 - val_loss: 0.1457 - val_mean_absolute_error: 0.2161\n",
      "Epoch 93/120\n",
      "15300/15300 [==============================] - 0s 17us/step - loss: 0.0573 - mean_absolute_error: 0.1496 - val_loss: 0.1494 - val_mean_absolute_error: 0.2262\n",
      "Epoch 94/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0563 - mean_absolute_error: 0.1486 - val_loss: 0.1416 - val_mean_absolute_error: 0.2141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0561 - mean_absolute_error: 0.1471 - val_loss: 0.1488 - val_mean_absolute_error: 0.2269\n",
      "Epoch 96/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0559 - mean_absolute_error: 0.1475 - val_loss: 0.1407 - val_mean_absolute_error: 0.2111\n",
      "Epoch 97/120\n",
      "15300/15300 [==============================] - 0s 18us/step - loss: 0.0561 - mean_absolute_error: 0.1481 - val_loss: 0.1410 - val_mean_absolute_error: 0.2131\n",
      "Epoch 98/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0559 - mean_absolute_error: 0.1485 - val_loss: 0.1400 - val_mean_absolute_error: 0.2134\n",
      "Epoch 99/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.0556 - mean_absolute_error: 0.1453 - val_loss: 0.1414 - val_mean_absolute_error: 0.2143\n",
      "Epoch 100/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.0581 - mean_absolute_error: 0.1522 - val_loss: 0.1447 - val_mean_absolute_error: 0.2226\n",
      "Epoch 101/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0557 - mean_absolute_error: 0.1481 - val_loss: 0.1395 - val_mean_absolute_error: 0.2140\n",
      "Epoch 102/120\n",
      "15300/15300 [==============================] - 0s 20us/step - loss: 0.0543 - mean_absolute_error: 0.1452 - val_loss: 0.1394 - val_mean_absolute_error: 0.2122\n",
      "Epoch 103/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0546 - mean_absolute_error: 0.1465 - val_loss: 0.1457 - val_mean_absolute_error: 0.2142\n",
      "Epoch 104/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0529 - mean_absolute_error: 0.1435 - val_loss: 0.1393 - val_mean_absolute_error: 0.2132\n",
      "Epoch 105/120\n",
      "15300/15300 [==============================] - 0s 18us/step - loss: 0.0527 - mean_absolute_error: 0.1437 - val_loss: 0.1405 - val_mean_absolute_error: 0.2110\n",
      "Epoch 106/120\n",
      "15300/15300 [==============================] - 0s 18us/step - loss: 0.0519 - mean_absolute_error: 0.1419 - val_loss: 0.1402 - val_mean_absolute_error: 0.2082\n",
      "Epoch 107/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0545 - mean_absolute_error: 0.1464 - val_loss: 0.1404 - val_mean_absolute_error: 0.2129\n",
      "Epoch 108/120\n",
      "15300/15300 [==============================] - 0s 19us/step - loss: 0.0568 - mean_absolute_error: 0.1518 - val_loss: 0.1408 - val_mean_absolute_error: 0.2161\n",
      "Epoch 109/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0514 - mean_absolute_error: 0.1419 - val_loss: 0.1401 - val_mean_absolute_error: 0.2105\n",
      "Epoch 110/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0521 - mean_absolute_error: 0.1430 - val_loss: 0.1436 - val_mean_absolute_error: 0.2213\n",
      "Epoch 111/120\n",
      "15300/15300 [==============================] - 0s 18us/step - loss: 0.0501 - mean_absolute_error: 0.1395 - val_loss: 0.1428 - val_mean_absolute_error: 0.2187\n",
      "Epoch 112/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0539 - mean_absolute_error: 0.1460 - val_loss: 0.1572 - val_mean_absolute_error: 0.2412\n",
      "Epoch 113/120\n",
      "15300/15300 [==============================] - 0s 11us/step - loss: 0.0528 - mean_absolute_error: 0.1445 - val_loss: 0.1440 - val_mean_absolute_error: 0.2123\n",
      "Epoch 114/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0545 - mean_absolute_error: 0.1476 - val_loss: 0.1407 - val_mean_absolute_error: 0.2123\n",
      "Epoch 115/120\n",
      "15300/15300 [==============================] - 0s 19us/step - loss: 0.0526 - mean_absolute_error: 0.1447 - val_loss: 0.1414 - val_mean_absolute_error: 0.2150\n",
      "Epoch 116/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0493 - mean_absolute_error: 0.1387 - val_loss: 0.1405 - val_mean_absolute_error: 0.2129\n",
      "Epoch 117/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0508 - mean_absolute_error: 0.1422 - val_loss: 0.1425 - val_mean_absolute_error: 0.2185\n",
      "Epoch 118/120\n",
      "15300/15300 [==============================] - 0s 20us/step - loss: 0.0557 - mean_absolute_error: 0.1497 - val_loss: 0.1439 - val_mean_absolute_error: 0.2223\n",
      "Epoch 119/120\n",
      "15300/15300 [==============================] - 0s 17us/step - loss: 0.0498 - mean_absolute_error: 0.1409 - val_loss: 0.1461 - val_mean_absolute_error: 0.2236\n",
      "Epoch 120/120\n",
      "15300/15300 [==============================] - 0s 19us/step - loss: 0.0496 - mean_absolute_error: 0.1396 - val_loss: 0.1367 - val_mean_absolute_error: 0.2070\n"
     ]
    }
   ],
   "source": [
    "# Train the FFNN model using training, error is measured using validation data:\n",
    "history = model.fit(X_train_sc, y_train, validation_data=(X_test_sc, y_test), epochs=120, \n",
    "                    batch_size=256) #, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.1169808 ],\n",
       "       [ 9.005494  ],\n",
       "       [11.2386875 ],\n",
       "       ...,\n",
       "       [ 0.33082515],\n",
       "       [ 4.5282393 ],\n",
       "       [ 0.48299447]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test_sc)  # generate predictions on validation data\n",
    "preds  # preview predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save training data loss and validation data loss as variables to plot:\n",
    "train_loss = history.history['loss']     # 'loss' = mean squared error of training data\n",
    "test_loss = history.history['val_loss']  # 'val_loss' = mean squared error of validation data\n",
    "\n",
    "# Plot training and testing loss for the FFNN model:\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(train_loss, label='Training loss', color='navy')\n",
    "plt.plot(test_loss, label='Testing loss', color='skyblue')\n",
    "plt.legend();\n",
    "\n",
    "# Save figure as a PNG file:\n",
    "plt.savefig('../../images/FFNN_fantasy_training_vs_testing_loss_function.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Assign predicted fantasy points to validation data as a new column:\n",
    "X_test['Predicted_FP'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Assign true fantasy points to validation data as a new column:\n",
    "X_test['FantasyPoints'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Week</th>\n",
       "      <th>PassingYards</th>\n",
       "      <th>PassingTouchdowns</th>\n",
       "      <th>PassingInterceptions</th>\n",
       "      <th>RushingYards</th>\n",
       "      <th>RushingTouchdowns</th>\n",
       "      <th>Receptions</th>\n",
       "      <th>ReceivingYards</th>\n",
       "      <th>...</th>\n",
       "      <th>Opponent_TB</th>\n",
       "      <th>Opponent_TEN</th>\n",
       "      <th>Opponent_WAS</th>\n",
       "      <th>Position_FB</th>\n",
       "      <th>Position_QB</th>\n",
       "      <th>Position_RB</th>\n",
       "      <th>Position_TE</th>\n",
       "      <th>Position_WR</th>\n",
       "      <th>Predicted_FP</th>\n",
       "      <th>FantasyPoints</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-11-29</th>\n",
       "      <td>181.0</td>\n",
       "      <td>Todd Gurley</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.116981</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-18</th>\n",
       "      <td>88.0</td>\n",
       "      <td>Mark Ingram</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.005494</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-20</th>\n",
       "      <td>70.0</td>\n",
       "      <td>Rob Gronkowski</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.238688</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-30</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Cole Beasley</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.389849</td>\n",
       "      <td>15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-25</th>\n",
       "      <td>189.0</td>\n",
       "      <td>Giovani Bernard</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.541089</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rank             Name  Week  PassingYards  PassingTouchdowns  \\\n",
       "Date                                                                        \n",
       "2015-11-29  181.0      Todd Gurley    12           0.0                0.0   \n",
       "2016-12-18   88.0      Mark Ingram    15           0.0                0.0   \n",
       "2015-12-20   70.0   Rob Gronkowski    15           0.0                0.0   \n",
       "2018-12-30   36.0     Cole Beasley    17           0.0                0.0   \n",
       "2018-11-25  189.0  Giovani Bernard    12           0.0                0.0   \n",
       "\n",
       "            PassingInterceptions  RushingYards  RushingTouchdowns  Receptions  \\\n",
       "Date                                                                            \n",
       "2015-11-29                   0.0          19.0                0.0         1.0   \n",
       "2016-12-18                   0.0          78.0                0.0         2.0   \n",
       "2015-12-20                   0.0           0.0                0.0         5.0   \n",
       "2018-12-30                   0.0           0.0                0.0         6.0   \n",
       "2018-11-25                   0.0          10.0                0.0         1.0   \n",
       "\n",
       "            ReceivingYards  ...  Opponent_TB  Opponent_TEN  Opponent_WAS  \\\n",
       "Date                        ...                                            \n",
       "2015-11-29            11.0  ...          0.0           0.0           0.0   \n",
       "2016-12-18            14.0  ...          0.0           0.0           0.0   \n",
       "2015-12-20            54.0  ...          0.0           1.0           0.0   \n",
       "2018-12-30            94.0  ...          0.0           0.0           0.0   \n",
       "2018-11-25            12.0  ...          0.0           0.0           0.0   \n",
       "\n",
       "            Position_FB  Position_QB  Position_RB  Position_TE  Position_WR  \\\n",
       "Date                                                                          \n",
       "2015-11-29          0.0          0.0          1.0          0.0          0.0   \n",
       "2016-12-18          0.0          0.0          1.0          0.0          0.0   \n",
       "2015-12-20          0.0          0.0          0.0          1.0          0.0   \n",
       "2018-12-30          0.0          0.0          0.0          0.0          1.0   \n",
       "2018-11-25          0.0          0.0          1.0          0.0          0.0   \n",
       "\n",
       "            Predicted_FP  FantasyPoints  \n",
       "Date                                     \n",
       "2015-11-29      3.116981            3.0  \n",
       "2016-12-18      9.005494            9.2  \n",
       "2015-12-20     11.238688           11.4  \n",
       "2018-12-30     15.389849           15.4  \n",
       "2018-11-25      2.541089            2.2  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()  # preview first 5 rows of validation data\n",
    "# Now, predicted fantasy points per week can be visually compared to true values and all other data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  0.13672210722974598\n",
      "RMSE =  0.36975952621906305\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display validation data MSE and RMSE:\n",
    "test_mse = mean_squared_error(preds, y_test)\n",
    "print('MSE = ', test_mse)\n",
    "print('RMSE = ', np.sqrt(test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  0.04340908383556789\n",
      "RMSE =  0.2083484673223393\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display training data MSE and RMSE:\n",
    "train_preds = model.predict(X_train_sc)\n",
    "train_mse = mean_squared_error(train_preds, y_train)\n",
    "print('MSE = ', train_mse)\n",
    "print('RMSE = ', np.sqrt(train_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
