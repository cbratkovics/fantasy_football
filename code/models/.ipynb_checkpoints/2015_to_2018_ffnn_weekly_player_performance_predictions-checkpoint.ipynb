{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# DataFrame manipulation libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Evaluation and processing libraries:\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Keras libraries:\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GRU\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Position</th>\n",
       "      <th>Week</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>PassingYards</th>\n",
       "      <th>PassingTouchdowns</th>\n",
       "      <th>PassingInterceptions</th>\n",
       "      <th>RushingYards</th>\n",
       "      <th>RushingTouchdowns</th>\n",
       "      <th>Receptions</th>\n",
       "      <th>ReceivingYards</th>\n",
       "      <th>ReceivingTouchdowns</th>\n",
       "      <th>FumblesLost</th>\n",
       "      <th>FantasyPoints</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>1</td>\n",
       "      <td>Carlos Hyde</td>\n",
       "      <td>SF</td>\n",
       "      <td>RB</td>\n",
       "      <td>1</td>\n",
       "      <td>MIN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.20</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>2</td>\n",
       "      <td>Tom Brady</td>\n",
       "      <td>NE</td>\n",
       "      <td>QB</td>\n",
       "      <td>1</td>\n",
       "      <td>PIT</td>\n",
       "      <td>288</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.62</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>3</td>\n",
       "      <td>Rob Gronkowski</td>\n",
       "      <td>NE</td>\n",
       "      <td>TE</td>\n",
       "      <td>1</td>\n",
       "      <td>PIT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.40</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>4</td>\n",
       "      <td>Julio Jones</td>\n",
       "      <td>ATL</td>\n",
       "      <td>WR</td>\n",
       "      <td>1</td>\n",
       "      <td>PHI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26.10</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>5</td>\n",
       "      <td>Carson Palmer</td>\n",
       "      <td>ARI</td>\n",
       "      <td>QB</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>307</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.68</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Rank            Name Team Position  Week Opponent  \\\n",
       "0  2015-09-13     1     Carlos Hyde   SF       RB     1      MIN   \n",
       "1  2015-09-13     2       Tom Brady   NE       QB     1      PIT   \n",
       "2  2015-09-13     3  Rob Gronkowski   NE       TE     1      PIT   \n",
       "3  2015-09-13     4     Julio Jones  ATL       WR     1      PHI   \n",
       "4  2015-09-13     5   Carson Palmer  ARI       QB     1       NO   \n",
       "\n",
       "   PassingYards  PassingTouchdowns  PassingInterceptions  RushingYards  \\\n",
       "0             0                  0                     0           168   \n",
       "1           288                  4                     0             1   \n",
       "2             0                  0                     0             0   \n",
       "3             0                  0                     0             0   \n",
       "4           307                  3                     0            14   \n",
       "\n",
       "   RushingTouchdowns  Receptions  ReceivingYards  ReceivingTouchdowns  \\\n",
       "0                  2           2              14                    0   \n",
       "1                  0           0               0                    0   \n",
       "2                  0           5              94                    3   \n",
       "3                  0           9             141                    2   \n",
       "4                  0           0               0                    0   \n",
       "\n",
       "   FumblesLost  FantasyPoints  Year  \n",
       "0            0          30.20  2015  \n",
       "1            0          27.62  2015  \n",
       "2            0          27.40  2015  \n",
       "3            0          26.10  2015  \n",
       "4            0          25.68  2015  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in CSV data of top player performance per week in the 2015, 2016, 2017, and 2018 NFL seasons:\n",
    "df = pd.read_csv('../../clean_data/weekly_player_performance_2015_to_2018.csv')\n",
    "df.head()  # preview first 5 rows of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                    datetime64[ns]\n",
       "Rank                             int64\n",
       "Name                            object\n",
       "Team                            object\n",
       "Position                        object\n",
       "Week                             int64\n",
       "Opponent                        object\n",
       "PassingYards                     int64\n",
       "PassingTouchdowns                int64\n",
       "PassingInterceptions             int64\n",
       "RushingYards                     int64\n",
       "RushingTouchdowns                int64\n",
       "Receptions                       int64\n",
       "ReceivingYards                   int64\n",
       "ReceivingTouchdowns              int64\n",
       "FumblesLost                      int64\n",
       "FantasyPoints                  float64\n",
       "Year                             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d') # Convert 'Date' feature into a Pandas datetime object\n",
    "df.dtypes  # examine data types of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Position</th>\n",
       "      <th>Week</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>PassingYards</th>\n",
       "      <th>PassingTouchdowns</th>\n",
       "      <th>PassingInterceptions</th>\n",
       "      <th>RushingYards</th>\n",
       "      <th>RushingTouchdowns</th>\n",
       "      <th>Receptions</th>\n",
       "      <th>ReceivingYards</th>\n",
       "      <th>ReceivingTouchdowns</th>\n",
       "      <th>FumblesLost</th>\n",
       "      <th>FantasyPoints</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-09-13</th>\n",
       "      <td>1</td>\n",
       "      <td>Carlos Hyde</td>\n",
       "      <td>SF</td>\n",
       "      <td>RB</td>\n",
       "      <td>1</td>\n",
       "      <td>MIN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.20</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-13</th>\n",
       "      <td>2</td>\n",
       "      <td>Tom Brady</td>\n",
       "      <td>NE</td>\n",
       "      <td>QB</td>\n",
       "      <td>1</td>\n",
       "      <td>PIT</td>\n",
       "      <td>288</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.62</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-13</th>\n",
       "      <td>3</td>\n",
       "      <td>Rob Gronkowski</td>\n",
       "      <td>NE</td>\n",
       "      <td>TE</td>\n",
       "      <td>1</td>\n",
       "      <td>PIT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.40</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-13</th>\n",
       "      <td>4</td>\n",
       "      <td>Julio Jones</td>\n",
       "      <td>ATL</td>\n",
       "      <td>WR</td>\n",
       "      <td>1</td>\n",
       "      <td>PHI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26.10</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-13</th>\n",
       "      <td>5</td>\n",
       "      <td>Carson Palmer</td>\n",
       "      <td>ARI</td>\n",
       "      <td>QB</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>307</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.68</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rank            Name Team Position  Week Opponent  PassingYards  \\\n",
       "Date                                                                          \n",
       "2015-09-13     1     Carlos Hyde   SF       RB     1      MIN             0   \n",
       "2015-09-13     2       Tom Brady   NE       QB     1      PIT           288   \n",
       "2015-09-13     3  Rob Gronkowski   NE       TE     1      PIT             0   \n",
       "2015-09-13     4     Julio Jones  ATL       WR     1      PHI             0   \n",
       "2015-09-13     5   Carson Palmer  ARI       QB     1       NO           307   \n",
       "\n",
       "            PassingTouchdowns  PassingInterceptions  RushingYards  \\\n",
       "Date                                                                \n",
       "2015-09-13                  0                     0           168   \n",
       "2015-09-13                  4                     0             1   \n",
       "2015-09-13                  0                     0             0   \n",
       "2015-09-13                  0                     0             0   \n",
       "2015-09-13                  3                     0            14   \n",
       "\n",
       "            RushingTouchdowns  Receptions  ReceivingYards  \\\n",
       "Date                                                        \n",
       "2015-09-13                  2           2              14   \n",
       "2015-09-13                  0           0               0   \n",
       "2015-09-13                  0           5              94   \n",
       "2015-09-13                  0           9             141   \n",
       "2015-09-13                  0           0               0   \n",
       "\n",
       "            ReceivingTouchdowns  FumblesLost  FantasyPoints  Year  \n",
       "Date                                                               \n",
       "2015-09-13                    0            0          30.20  2015  \n",
       "2015-09-13                    0            0          27.62  2015  \n",
       "2015-09-13                    3            0          27.40  2015  \n",
       "2015-09-13                    2            0          26.10  2015  \n",
       "2015-09-13                    0            0          25.68  2015  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('Date', inplace=True)  # set Date as the index\n",
    "df.sort_index(inplace=True)         # sort the dataframe by the Date index\n",
    "df.head()                           # examine first 5 rows to verify changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20400, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape  # preview dataframe dimensions; 20,400 rows and 17 columns as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert player's team, opponent, and position into one-hot encoded variables to use for FFNN:\n",
    "df_with_dummies = pd.get_dummies(df, columns=['Team', 'Opponent', 'Position'], drop_first=False)\n",
    "\n",
    "# Select feature variables to convert into floats; prevents errors when scaling data with StandardScaler:\n",
    "features = [col for col in df_with_dummies.columns if col not in ['Name', 'Week']]\n",
    "df_with_dummies[features] = df_with_dummies[features].astype(float)\n",
    "\n",
    "# Assign X as features to be used for predicting weekly fantasy points per player:\n",
    "X = df_with_dummies[[col for col in df_with_dummies.columns if col != 'FantasyPoints']]\n",
    "# Assign target vector y as weekly fantasy points per player:\n",
    "y = df_with_dummies['FantasyPoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rank                    float64\n",
       "Name                     object\n",
       "Week                      int64\n",
       "PassingYards            float64\n",
       "PassingTouchdowns       float64\n",
       "PassingInterceptions    float64\n",
       "RushingYards            float64\n",
       "RushingTouchdowns       float64\n",
       "Receptions              float64\n",
       "ReceivingYards          float64\n",
       "ReceivingTouchdowns     float64\n",
       "FumblesLost             float64\n",
       "Year                    float64\n",
       "Team_ARI                float64\n",
       "Team_ATL                float64\n",
       "Team_BAL                float64\n",
       "Team_BUF                float64\n",
       "Team_CAR                float64\n",
       "Team_CHI                float64\n",
       "Team_CIN                float64\n",
       "Team_CLE                float64\n",
       "Team_DAL                float64\n",
       "Team_DEN                float64\n",
       "Team_DET                float64\n",
       "Team_GB                 float64\n",
       "Team_HOU                float64\n",
       "Team_IND                float64\n",
       "Team_JAX                float64\n",
       "Team_KC                 float64\n",
       "Team_LAC                float64\n",
       "                         ...   \n",
       "Opponent_CLE            float64\n",
       "Opponent_DAL            float64\n",
       "Opponent_DEN            float64\n",
       "Opponent_DET            float64\n",
       "Opponent_GB             float64\n",
       "Opponent_HOU            float64\n",
       "Opponent_IND            float64\n",
       "Opponent_JAX            float64\n",
       "Opponent_KC             float64\n",
       "Opponent_LAC            float64\n",
       "Opponent_LAR            float64\n",
       "Opponent_MIA            float64\n",
       "Opponent_MIN            float64\n",
       "Opponent_NE             float64\n",
       "Opponent_NO             float64\n",
       "Opponent_NYG            float64\n",
       "Opponent_NYJ            float64\n",
       "Opponent_OAK            float64\n",
       "Opponent_PHI            float64\n",
       "Opponent_PIT            float64\n",
       "Opponent_SEA            float64\n",
       "Opponent_SF             float64\n",
       "Opponent_TB             float64\n",
       "Opponent_TEN            float64\n",
       "Opponent_WAS            float64\n",
       "Position_FB             float64\n",
       "Position_QB             float64\n",
       "Position_RB             float64\n",
       "Position_TE             float64\n",
       "Position_WR             float64\n",
       "Length: 82, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes  # verify that data types have been properly cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y data into a training set and validation set:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all columns to use as predictive features using StandardScaler:\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train.drop(columns = ['Name', 'Week']))\n",
    "X_test_sc = ss.transform(X_test.drop(columns = ['Name', 'Week']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40830156, -0.32569876, -0.26948036, -0.21607813,  0.32653258,\n",
       "        -0.25192244, -0.51896593, -0.4531034 , -0.38336799, -0.20342918,\n",
       "        -1.34067133, -0.17684817, -0.18644735, -0.18700964, -0.18794355,\n",
       "        -0.17860924, -0.17487318, -0.17207467, -0.17684817, -0.17606051,\n",
       "        -0.18093394, -0.17724085, -0.17625772, -0.18112649, -0.17546773,\n",
       "        -0.17880398, -0.17625772, -0.17684817,  5.87357131, -0.17880398,\n",
       "        -0.17958107, -0.18663494, -0.18151105, -0.17977488, -0.17507156,\n",
       "        -0.18757046, -0.18304223, -0.17996851, -0.18112649, -0.18246935,\n",
       "        -0.1818949 , -0.18074121, -0.17782843, -0.1818949 , -0.18437293,\n",
       "        -0.18151105, -0.18380366, -0.17938707, -0.17841432,  5.4976804 ,\n",
       "        -0.18285144, -0.18285144, -0.17327891, -0.18112649, -0.17821921,\n",
       "        -0.17821921, -0.18361356, -0.17821921, -0.17899853, -0.17919289,\n",
       "        -0.17880398, -0.18112649, -0.17841432, -0.18074121, -0.17782843,\n",
       "        -0.17802392, -0.18456235, -0.18035522, -0.17802392, -0.17763276,\n",
       "        -0.17066021, -0.17625772, -0.17958107, -0.18035522, -0.17645473,\n",
       "        -0.17724085, -0.36399787,  1.68791487, -0.5021437 , -0.80189852],\n",
       "       [-0.70924942, -0.32569876, -0.26948036, -0.21607813,  2.73555666,\n",
       "        -0.25192244, -0.09110847, -0.3581574 , -0.38336799, -0.20342918,\n",
       "        -0.4468515 , -0.17684817, -0.18644735, -0.18700964, -0.18794355,\n",
       "        -0.17860924, -0.17487318, -0.17207467, -0.17684817, -0.17606051,\n",
       "        -0.18093394, -0.17724085, -0.17625772, -0.18112649, -0.17546773,\n",
       "        -0.17880398, -0.17625772, -0.17684817, -0.17025417, -0.17880398,\n",
       "        -0.17958107, -0.18663494,  5.50930658, -0.17977488, -0.17507156,\n",
       "        -0.18757046, -0.18304223, -0.17996851, -0.18112649, -0.18246935,\n",
       "        -0.1818949 , -0.18074121, -0.17782843,  5.4976804 , -0.18437293,\n",
       "        -0.18151105, -0.18380366, -0.17938707, -0.17841432, -0.1818949 ,\n",
       "        -0.18285144, -0.18285144, -0.17327891, -0.18112649, -0.17821921,\n",
       "        -0.17821921, -0.18361356, -0.17821921, -0.17899853, -0.17919289,\n",
       "        -0.17880398, -0.18112649, -0.17841432, -0.18074121, -0.17782843,\n",
       "        -0.17802392, -0.18456235, -0.18035522, -0.17802392, -0.17763276,\n",
       "        -0.17066021, -0.17625772, -0.17958107, -0.18035522, -0.17645473,\n",
       "        -0.17724085, -0.36399787,  1.68791487, -0.5021437 , -0.80189852],\n",
       "       [-0.9255496 , -0.32569876, -0.26948036, -0.21607813, -0.44925484,\n",
       "        -0.25192244,  1.19246392,  0.90778923,  2.06060297, -0.20342918,\n",
       "        -1.34067133, -0.17684817, -0.18644735, -0.18700964, -0.18794355,\n",
       "        -0.17860924, -0.17487318, -0.17207467, -0.17684817, -0.17606051,\n",
       "        -0.18093394, -0.17724085, -0.17625772, -0.18112649, -0.17546773,\n",
       "        -0.17880398, -0.17625772, -0.17684817, -0.17025417, -0.17880398,\n",
       "        -0.17958107,  5.35805355, -0.18151105, -0.17977488, -0.17507156,\n",
       "        -0.18757046, -0.18304223, -0.17996851, -0.18112649, -0.18246935,\n",
       "        -0.1818949 , -0.18074121, -0.17782843, -0.1818949 , -0.18437293,\n",
       "        -0.18151105, -0.18380366, -0.17938707, -0.17841432, -0.1818949 ,\n",
       "        -0.18285144, -0.18285144, -0.17327891, -0.18112649, -0.17821921,\n",
       "        -0.17821921, -0.18361356, -0.17821921, -0.17899853, -0.17919289,\n",
       "        -0.17880398, -0.18112649, -0.17841432, -0.18074121, -0.17782843,\n",
       "        -0.17802392, -0.18456235, -0.18035522, -0.17802392, -0.17763276,\n",
       "        -0.17066021, -0.17625772, -0.17958107,  5.54461348, -0.17645473,\n",
       "        -0.17724085, -0.36399787, -0.59244694,  1.99146181, -0.80189852],\n",
       "       [-1.33411663, -0.32569876, -0.26948036, -0.21607813, -0.44925484,\n",
       "        -0.25192244,  1.62032138,  2.17373587,  2.06060297, -0.20342918,\n",
       "         1.34078817, -0.17684817, -0.18644735, -0.18700964, -0.18794355,\n",
       "        -0.17860924, -0.17487318, -0.17207467, -0.17684817,  5.67986528,\n",
       "        -0.18093394, -0.17724085, -0.17625772, -0.18112649, -0.17546773,\n",
       "        -0.17880398, -0.17625772, -0.17684817, -0.17025417, -0.17880398,\n",
       "        -0.17958107, -0.18663494, -0.18151105, -0.17977488, -0.17507156,\n",
       "        -0.18757046, -0.18304223, -0.17996851, -0.18112649, -0.18246935,\n",
       "        -0.1818949 , -0.18074121, -0.17782843, -0.1818949 , -0.18437293,\n",
       "        -0.18151105, -0.18380366, -0.17938707, -0.17841432, -0.1818949 ,\n",
       "        -0.18285144, -0.18285144, -0.17327891, -0.18112649, -0.17821921,\n",
       "        -0.17821921, -0.18361356, -0.17821921, -0.17899853, -0.17919289,\n",
       "        -0.17880398, -0.18112649, -0.17841432, -0.18074121, -0.17782843,\n",
       "         5.61722276, -0.18456235, -0.18035522, -0.17802392, -0.17763276,\n",
       "        -0.17066021, -0.17625772, -0.17958107, -0.18035522, -0.17645473,\n",
       "        -0.17724085, -0.36399787, -0.59244694, -0.5021437 ,  1.24704058],\n",
       "       [ 0.50443497, -0.32569876, -0.26948036, -0.21607813, -0.04094567,\n",
       "        -0.25192244, -0.51896593, -0.42145473, -0.38336799, -0.20342918,\n",
       "         1.34078817, -0.17684817, -0.18644735, -0.18700964, -0.18794355,\n",
       "        -0.17860924, -0.17487318,  5.81143074, -0.17684817, -0.17606051,\n",
       "        -0.18093394, -0.17724085, -0.17625772, -0.18112649, -0.17546773,\n",
       "        -0.17880398, -0.17625772, -0.17684817, -0.17025417, -0.17880398,\n",
       "        -0.17958107, -0.18663494, -0.18151105, -0.17977488, -0.17507156,\n",
       "        -0.18757046, -0.18304223, -0.17996851, -0.18112649, -0.18246935,\n",
       "        -0.1818949 , -0.18074121, -0.17782843, -0.1818949 , -0.18437293,\n",
       "        -0.18151105, -0.18380366, -0.17938707, -0.17841432, -0.1818949 ,\n",
       "         5.46892045, -0.18285144, -0.17327891, -0.18112649, -0.17821921,\n",
       "        -0.17821921, -0.18361356, -0.17821921, -0.17899853, -0.17919289,\n",
       "        -0.17880398, -0.18112649, -0.17841432, -0.18074121, -0.17782843,\n",
       "        -0.17802392, -0.18456235, -0.18035522, -0.17802392, -0.17763276,\n",
       "        -0.17066021, -0.17625772, -0.17958107, -0.18035522, -0.17645473,\n",
       "        -0.17724085, -0.36399787,  1.68791487, -0.5021437 , -0.80189852]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sc[0:5]  # preview first 5 scaled X values in the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5100, 80)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sc.shape  # check shape of scaled X validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and build feed-forward neural network to predict player performance per week:\n",
    "model = Sequential()                                        # instantiate model\n",
    "model.add(Dense(80, activation='relu', input_shape=(80,)))  # input layer with 80 neurons\n",
    "model.add(Dense(40, activation='relu'))                     # first hidden layer with 40 neurons\n",
    "model.add(Dense(20, activation='relu'))                     # second hidden layer with 20 neurons\n",
    "model.add(Dense(10, activation='relu'))                     # third hidden layer with 10 neurons\n",
    "model.add(Dense(5, activation='relu'))                      # fourth hidden layer with 5 neurons\n",
    "model.add(Dense(1))                                         # output layer with 1 neuron; represents predicted points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the FFNN model:\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "# loss function = mean squared error\n",
    "# optimization function = adam\n",
    "# evaluation metric = mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 15300 samples, validate on 5100 samples\n",
      "Epoch 1/120\n",
      "15300/15300 [==============================] - 1s 39us/step - loss: 39.1753 - mean_absolute_error: 4.3038 - val_loss: 8.9072 - val_mean_absolute_error: 2.3253\n",
      "Epoch 2/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 3.2258 - mean_absolute_error: 1.2715 - val_loss: 1.2733 - val_mean_absolute_error: 0.8372\n",
      "Epoch 3/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.9899 - mean_absolute_error: 0.7497 - val_loss: 0.8153 - val_mean_absolute_error: 0.6801\n",
      "Epoch 4/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.6642 - mean_absolute_error: 0.6147 - val_loss: 0.6222 - val_mean_absolute_error: 0.5894\n",
      "Epoch 5/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.5031 - mean_absolute_error: 0.5338 - val_loss: 0.5180 - val_mean_absolute_error: 0.5324\n",
      "Epoch 6/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.4030 - mean_absolute_error: 0.4766 - val_loss: 0.4498 - val_mean_absolute_error: 0.4917\n",
      "Epoch 7/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.3455 - mean_absolute_error: 0.4408 - val_loss: 0.4020 - val_mean_absolute_error: 0.4649\n",
      "Epoch 8/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.2971 - mean_absolute_error: 0.4073 - val_loss: 0.3660 - val_mean_absolute_error: 0.4398\n",
      "Epoch 9/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.2657 - mean_absolute_error: 0.3852 - val_loss: 0.3411 - val_mean_absolute_error: 0.4201\n",
      "Epoch 10/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.2403 - mean_absolute_error: 0.3643 - val_loss: 0.3200 - val_mean_absolute_error: 0.4062\n",
      "Epoch 11/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.2232 - mean_absolute_error: 0.3514 - val_loss: 0.3030 - val_mean_absolute_error: 0.3937\n",
      "Epoch 12/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.2054 - mean_absolute_error: 0.3353 - val_loss: 0.2876 - val_mean_absolute_error: 0.3806\n",
      "Epoch 13/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.1899 - mean_absolute_error: 0.3215 - val_loss: 0.2777 - val_mean_absolute_error: 0.3726\n",
      "Epoch 14/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.1826 - mean_absolute_error: 0.3152 - val_loss: 0.2692 - val_mean_absolute_error: 0.3622\n",
      "Epoch 15/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.1704 - mean_absolute_error: 0.3030 - val_loss: 0.2594 - val_mean_absolute_error: 0.3571\n",
      "Epoch 16/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.1630 - mean_absolute_error: 0.2947 - val_loss: 0.2550 - val_mean_absolute_error: 0.3535\n",
      "Epoch 17/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.1552 - mean_absolute_error: 0.2878 - val_loss: 0.2468 - val_mean_absolute_error: 0.3448\n",
      "Epoch 18/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.1506 - mean_absolute_error: 0.2832 - val_loss: 0.2418 - val_mean_absolute_error: 0.3364\n",
      "Epoch 19/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.1432 - mean_absolute_error: 0.2757 - val_loss: 0.2371 - val_mean_absolute_error: 0.3354\n",
      "Epoch 20/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.1385 - mean_absolute_error: 0.2683 - val_loss: 0.2330 - val_mean_absolute_error: 0.3308\n",
      "Epoch 21/120\n",
      "15300/15300 [==============================] - 0s 21us/step - loss: 0.1336 - mean_absolute_error: 0.2640 - val_loss: 0.2275 - val_mean_absolute_error: 0.3237\n",
      "Epoch 22/120\n",
      "15300/15300 [==============================] - 0s 19us/step - loss: 0.1298 - mean_absolute_error: 0.2593 - val_loss: 0.2237 - val_mean_absolute_error: 0.3231\n",
      "Epoch 23/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.1268 - mean_absolute_error: 0.2563 - val_loss: 0.2225 - val_mean_absolute_error: 0.3180\n",
      "Epoch 24/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.1215 - mean_absolute_error: 0.2499 - val_loss: 0.2210 - val_mean_absolute_error: 0.3148\n",
      "Epoch 25/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.1202 - mean_absolute_error: 0.2478 - val_loss: 0.2135 - val_mean_absolute_error: 0.3122\n",
      "Epoch 26/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.1158 - mean_absolute_error: 0.2418 - val_loss: 0.2146 - val_mean_absolute_error: 0.3078\n",
      "Epoch 27/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.1143 - mean_absolute_error: 0.2392 - val_loss: 0.2079 - val_mean_absolute_error: 0.3025\n",
      "Epoch 28/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.1108 - mean_absolute_error: 0.2354 - val_loss: 0.2090 - val_mean_absolute_error: 0.3060\n",
      "Epoch 29/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.1083 - mean_absolute_error: 0.2322 - val_loss: 0.2095 - val_mean_absolute_error: 0.3080\n",
      "Epoch 30/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.1065 - mean_absolute_error: 0.2300 - val_loss: 0.2032 - val_mean_absolute_error: 0.2976\n",
      "Epoch 31/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.1050 - mean_absolute_error: 0.2274 - val_loss: 0.2028 - val_mean_absolute_error: 0.2968\n",
      "Epoch 32/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.1015 - mean_absolute_error: 0.2241 - val_loss: 0.1991 - val_mean_absolute_error: 0.2957\n",
      "Epoch 33/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0998 - mean_absolute_error: 0.2203 - val_loss: 0.1984 - val_mean_absolute_error: 0.2940\n",
      "Epoch 34/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0980 - mean_absolute_error: 0.2176 - val_loss: 0.1996 - val_mean_absolute_error: 0.2937\n",
      "Epoch 35/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0959 - mean_absolute_error: 0.2162 - val_loss: 0.1968 - val_mean_absolute_error: 0.2867\n",
      "Epoch 36/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.0935 - mean_absolute_error: 0.2126 - val_loss: 0.1913 - val_mean_absolute_error: 0.2822\n",
      "Epoch 37/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0911 - mean_absolute_error: 0.2089 - val_loss: 0.1931 - val_mean_absolute_error: 0.2842\n",
      "Epoch 38/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0920 - mean_absolute_error: 0.2093 - val_loss: 0.1926 - val_mean_absolute_error: 0.2824\n",
      "Epoch 39/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0897 - mean_absolute_error: 0.2066 - val_loss: 0.1934 - val_mean_absolute_error: 0.2841\n",
      "Epoch 40/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0882 - mean_absolute_error: 0.2057 - val_loss: 0.1910 - val_mean_absolute_error: 0.2830\n",
      "Epoch 41/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0881 - mean_absolute_error: 0.2046 - val_loss: 0.1871 - val_mean_absolute_error: 0.2771\n",
      "Epoch 42/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0858 - mean_absolute_error: 0.2012 - val_loss: 0.1858 - val_mean_absolute_error: 0.2738\n",
      "Epoch 43/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0847 - mean_absolute_error: 0.1998 - val_loss: 0.1898 - val_mean_absolute_error: 0.2751\n",
      "Epoch 44/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0838 - mean_absolute_error: 0.1982 - val_loss: 0.1864 - val_mean_absolute_error: 0.2754\n",
      "Epoch 45/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0821 - mean_absolute_error: 0.1966 - val_loss: 0.1855 - val_mean_absolute_error: 0.2695\n",
      "Epoch 46/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0839 - mean_absolute_error: 0.1973 - val_loss: 0.1819 - val_mean_absolute_error: 0.2698\n",
      "Epoch 47/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0806 - mean_absolute_error: 0.1939 - val_loss: 0.1857 - val_mean_absolute_error: 0.2699\n",
      "Epoch 48/120\n",
      "15300/15300 [==============================] - 0s 12us/step - loss: 0.0793 - mean_absolute_error: 0.1916 - val_loss: 0.1834 - val_mean_absolute_error: 0.2716\n",
      "Epoch 49/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0775 - mean_absolute_error: 0.1894 - val_loss: 0.1861 - val_mean_absolute_error: 0.2726\n",
      "Epoch 50/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0795 - mean_absolute_error: 0.1922 - val_loss: 0.1840 - val_mean_absolute_error: 0.2716\n",
      "Epoch 51/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0781 - mean_absolute_error: 0.1889 - val_loss: 0.1813 - val_mean_absolute_error: 0.2687\n",
      "Epoch 52/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0764 - mean_absolute_error: 0.1870 - val_loss: 0.1838 - val_mean_absolute_error: 0.2733\n",
      "Epoch 53/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0750 - mean_absolute_error: 0.1852 - val_loss: 0.1809 - val_mean_absolute_error: 0.2699\n",
      "Epoch 54/120\n",
      "15300/15300 [==============================] - 0s 19us/step - loss: 0.0749 - mean_absolute_error: 0.1847 - val_loss: 0.1792 - val_mean_absolute_error: 0.2634\n",
      "Epoch 55/120\n",
      "15300/15300 [==============================] - 0s 22us/step - loss: 0.0728 - mean_absolute_error: 0.1819 - val_loss: 0.1797 - val_mean_absolute_error: 0.2647\n",
      "Epoch 56/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0719 - mean_absolute_error: 0.1810 - val_loss: 0.1827 - val_mean_absolute_error: 0.2640\n",
      "Epoch 57/120\n",
      "15300/15300 [==============================] - 0s 17us/step - loss: 0.0715 - mean_absolute_error: 0.1812 - val_loss: 0.1804 - val_mean_absolute_error: 0.2673\n",
      "Epoch 58/120\n",
      "15300/15300 [==============================] - 0s 17us/step - loss: 0.0701 - mean_absolute_error: 0.1781 - val_loss: 0.1775 - val_mean_absolute_error: 0.2594\n",
      "Epoch 59/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0698 - mean_absolute_error: 0.1785 - val_loss: 0.1798 - val_mean_absolute_error: 0.2618\n",
      "Epoch 60/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0688 - mean_absolute_error: 0.1758 - val_loss: 0.1793 - val_mean_absolute_error: 0.2602\n",
      "Epoch 61/120\n",
      "15300/15300 [==============================] - 0s 22us/step - loss: 0.0711 - mean_absolute_error: 0.1792 - val_loss: 0.1858 - val_mean_absolute_error: 0.2621\n",
      "Epoch 62/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0697 - mean_absolute_error: 0.1772 - val_loss: 0.1791 - val_mean_absolute_error: 0.2644\n",
      "Epoch 63/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0684 - mean_absolute_error: 0.1766 - val_loss: 0.1807 - val_mean_absolute_error: 0.2613\n",
      "Epoch 64/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0666 - mean_absolute_error: 0.1732 - val_loss: 0.1755 - val_mean_absolute_error: 0.2555\n",
      "Epoch 65/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.0649 - mean_absolute_error: 0.1703 - val_loss: 0.1743 - val_mean_absolute_error: 0.2547\n",
      "Epoch 66/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0644 - mean_absolute_error: 0.1702 - val_loss: 0.1794 - val_mean_absolute_error: 0.2552\n",
      "Epoch 67/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0641 - mean_absolute_error: 0.1681 - val_loss: 0.1791 - val_mean_absolute_error: 0.2593\n",
      "Epoch 68/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0648 - mean_absolute_error: 0.1705 - val_loss: 0.1766 - val_mean_absolute_error: 0.2575\n",
      "Epoch 69/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0625 - mean_absolute_error: 0.1665 - val_loss: 0.1749 - val_mean_absolute_error: 0.2536\n",
      "Epoch 70/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0628 - mean_absolute_error: 0.1669 - val_loss: 0.1773 - val_mean_absolute_error: 0.2569\n",
      "Epoch 71/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0650 - mean_absolute_error: 0.1724 - val_loss: 0.1783 - val_mean_absolute_error: 0.2548\n",
      "Epoch 72/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0638 - mean_absolute_error: 0.1700 - val_loss: 0.1726 - val_mean_absolute_error: 0.2513\n",
      "Epoch 73/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.0603 - mean_absolute_error: 0.1641 - val_loss: 0.1754 - val_mean_absolute_error: 0.2535\n",
      "Epoch 74/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.0604 - mean_absolute_error: 0.1634 - val_loss: 0.1746 - val_mean_absolute_error: 0.2522\n",
      "Epoch 75/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0589 - mean_absolute_error: 0.1616 - val_loss: 0.1761 - val_mean_absolute_error: 0.2536\n",
      "Epoch 76/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0590 - mean_absolute_error: 0.1621 - val_loss: 0.1731 - val_mean_absolute_error: 0.2524\n",
      "Epoch 77/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0580 - mean_absolute_error: 0.1601 - val_loss: 0.1800 - val_mean_absolute_error: 0.2607\n",
      "Epoch 78/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0605 - mean_absolute_error: 0.1640 - val_loss: 0.1834 - val_mean_absolute_error: 0.2564\n",
      "Epoch 79/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0609 - mean_absolute_error: 0.1657 - val_loss: 0.1724 - val_mean_absolute_error: 0.2496\n",
      "Epoch 80/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0574 - mean_absolute_error: 0.1599 - val_loss: 0.1811 - val_mean_absolute_error: 0.2517\n",
      "Epoch 81/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0568 - mean_absolute_error: 0.1586 - val_loss: 0.1709 - val_mean_absolute_error: 0.2477\n",
      "Epoch 82/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0611 - mean_absolute_error: 0.1657 - val_loss: 0.1764 - val_mean_absolute_error: 0.2539\n",
      "Epoch 83/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0577 - mean_absolute_error: 0.1608 - val_loss: 0.1703 - val_mean_absolute_error: 0.2469\n",
      "Epoch 84/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0571 - mean_absolute_error: 0.1609 - val_loss: 0.1802 - val_mean_absolute_error: 0.2652\n",
      "Epoch 85/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0553 - mean_absolute_error: 0.1567 - val_loss: 0.1708 - val_mean_absolute_error: 0.2476\n",
      "Epoch 86/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0530 - mean_absolute_error: 0.1536 - val_loss: 0.1743 - val_mean_absolute_error: 0.2497\n",
      "Epoch 87/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0537 - mean_absolute_error: 0.1549 - val_loss: 0.1733 - val_mean_absolute_error: 0.2494\n",
      "Epoch 88/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0552 - mean_absolute_error: 0.1575 - val_loss: 0.1735 - val_mean_absolute_error: 0.2495\n",
      "Epoch 89/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0524 - mean_absolute_error: 0.1526 - val_loss: 0.1675 - val_mean_absolute_error: 0.2460\n",
      "Epoch 90/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0505 - mean_absolute_error: 0.1483 - val_loss: 0.1757 - val_mean_absolute_error: 0.2493\n",
      "Epoch 91/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0523 - mean_absolute_error: 0.1539 - val_loss: 0.1689 - val_mean_absolute_error: 0.2471\n",
      "Epoch 92/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0509 - mean_absolute_error: 0.1511 - val_loss: 0.1697 - val_mean_absolute_error: 0.2470\n",
      "Epoch 93/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0531 - mean_absolute_error: 0.1546 - val_loss: 0.1718 - val_mean_absolute_error: 0.2511\n",
      "Epoch 94/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0526 - mean_absolute_error: 0.1542 - val_loss: 0.1725 - val_mean_absolute_error: 0.2510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.0523 - mean_absolute_error: 0.1535 - val_loss: 0.1752 - val_mean_absolute_error: 0.2568\n",
      "Epoch 96/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0510 - mean_absolute_error: 0.1518 - val_loss: 0.1719 - val_mean_absolute_error: 0.2469\n",
      "Epoch 97/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0506 - mean_absolute_error: 0.1518 - val_loss: 0.1710 - val_mean_absolute_error: 0.2474\n",
      "Epoch 98/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0497 - mean_absolute_error: 0.1489 - val_loss: 0.1678 - val_mean_absolute_error: 0.2467\n",
      "Epoch 99/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0471 - mean_absolute_error: 0.1454 - val_loss: 0.1740 - val_mean_absolute_error: 0.2467\n",
      "Epoch 100/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.0495 - mean_absolute_error: 0.1514 - val_loss: 0.1749 - val_mean_absolute_error: 0.2462\n",
      "Epoch 101/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0462 - mean_absolute_error: 0.1443 - val_loss: 0.1711 - val_mean_absolute_error: 0.2440\n",
      "Epoch 102/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0462 - mean_absolute_error: 0.1438 - val_loss: 0.1681 - val_mean_absolute_error: 0.2449\n",
      "Epoch 103/120\n",
      "15300/15300 [==============================] - 0s 16us/step - loss: 0.0462 - mean_absolute_error: 0.1447 - val_loss: 0.1693 - val_mean_absolute_error: 0.2430\n",
      "Epoch 104/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0470 - mean_absolute_error: 0.1462 - val_loss: 0.1670 - val_mean_absolute_error: 0.2446\n",
      "Epoch 105/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0463 - mean_absolute_error: 0.1455 - val_loss: 0.1698 - val_mean_absolute_error: 0.2498\n",
      "Epoch 106/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0464 - mean_absolute_error: 0.1451 - val_loss: 0.1758 - val_mean_absolute_error: 0.2607\n",
      "Epoch 107/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0449 - mean_absolute_error: 0.1422 - val_loss: 0.1641 - val_mean_absolute_error: 0.2385\n",
      "Epoch 108/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0465 - mean_absolute_error: 0.1448 - val_loss: 0.1692 - val_mean_absolute_error: 0.2514\n",
      "Epoch 109/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0429 - mean_absolute_error: 0.1392 - val_loss: 0.1681 - val_mean_absolute_error: 0.2425\n",
      "Epoch 110/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0431 - mean_absolute_error: 0.1399 - val_loss: 0.1666 - val_mean_absolute_error: 0.2488\n",
      "Epoch 111/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0424 - mean_absolute_error: 0.1383 - val_loss: 0.1669 - val_mean_absolute_error: 0.2447\n",
      "Epoch 112/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0438 - mean_absolute_error: 0.1399 - val_loss: 0.1662 - val_mean_absolute_error: 0.2426\n",
      "Epoch 113/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0454 - mean_absolute_error: 0.1446 - val_loss: 0.1643 - val_mean_absolute_error: 0.2412\n",
      "Epoch 114/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0417 - mean_absolute_error: 0.1373 - val_loss: 0.1820 - val_mean_absolute_error: 0.2654\n",
      "Epoch 115/120\n",
      "15300/15300 [==============================] - 0s 14us/step - loss: 0.0437 - mean_absolute_error: 0.1416 - val_loss: 0.1675 - val_mean_absolute_error: 0.2418\n",
      "Epoch 116/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0423 - mean_absolute_error: 0.1393 - val_loss: 0.1672 - val_mean_absolute_error: 0.2387\n",
      "Epoch 117/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0432 - mean_absolute_error: 0.1401 - val_loss: 0.1659 - val_mean_absolute_error: 0.2434\n",
      "Epoch 118/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0413 - mean_absolute_error: 0.1360 - val_loss: 0.1719 - val_mean_absolute_error: 0.2412\n",
      "Epoch 119/120\n",
      "15300/15300 [==============================] - 0s 15us/step - loss: 0.0450 - mean_absolute_error: 0.1438 - val_loss: 0.1689 - val_mean_absolute_error: 0.2505\n",
      "Epoch 120/120\n",
      "15300/15300 [==============================] - 0s 13us/step - loss: 0.0400 - mean_absolute_error: 0.1343 - val_loss: 0.1684 - val_mean_absolute_error: 0.2457\n"
     ]
    }
   ],
   "source": [
    "# Train the FFNN model using training, error is measured using validation data:\n",
    "history = model.fit(X_train_sc, y_train, validation_data=(X_test_sc, y_test), epochs=120, \n",
    "                    batch_size=256) #, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.2340932 ],\n",
       "       [ 9.066443  ],\n",
       "       [11.50455   ],\n",
       "       ...,\n",
       "       [ 0.42620364],\n",
       "       [ 4.2488117 ],\n",
       "       [ 0.5777705 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test_sc)  # generate predictions on validation data\n",
    "preds  # preview predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAJCCAYAAACxozTkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3X+UZHV9J/z3t6pmpoFBRnF0XIYs/ooRUSbjSBRZNWjyaBJjstGzESVu4h6Ss9msPq7PinmSE3Wz52iyq4YkG5c1GJ+jT4iR8OjJxrjG1WQNKzooAkIIalBGQQYM8kMG6K7v80fd6q6uqWaGmem+l+nX65w+VXX7/vjWvVXV/b7f7/1UqbUGAACA7ui13QAAAACWE9QAAAA6RlADAADoGEENAACgYwQ1AACAjhHUAAAAOkZQAwAA6BhBDQAAoGMENQAAgI4ZrOXGHv3oR9dTTjllLTcJAADQGVdcccVttdatB5pvTYPaKaeckt27d6/lJgEAADqjlPL1g5nP0EcAAICOEdQAAAA6RlADAADomDW9Rg0AAFg9DzzwQPbs2ZN9+/a13ZR1b25uLtu3b8+GDRsOaXlBDQAAjhJ79uzJ8ccfn1NOOSWllLabs27VWnP77bdnz549efzjH39I6zD0EQAAjhL79u3LiSeeKKS1rJSSE0888bB6NgU1AAA4ighp3XC4x0FQAwAA6BhBDQAAOCJuv/327NixIzt27Mi2bdty0kknLT6+//77D2odP//zP5/rr7/+Qef5/d///Xzwgx88Ek3OWWedlSuvvPKIrOtIOuhiIqWUfpLdSb5Za/2JUsrjk1yc5FFJvpDk3Frrwe19AADgqHPiiScuhp63vOUt2bx5c974xjcum6fWmlprer3ZfUbve9/7DridX/7lXz78xnbcQ+lRe12S6yYevyPJu2qtT07yj0leeyQbBgAAHB2+8pWv5LTTTssv/dIvZefOnbn55ptz3nnnZdeuXXna056Wt73tbYvzjnu45ufns2XLlpx//vk5/fTT85znPCe33nprkuTXfu3X8u53v3tx/vPPPz9nnHFGnvKUp+Syyy5Lktxzzz35mZ/5mZx++ul55StfmV27dh2w5+wDH/hAnv70p+e0007Lr/7qryZJ5ufnc+655y5Ov+CCC5Ik73rXu3Lqqafm9NNPz6tf/eojvs8OqketlLI9yY8n+Y9J3lBGV8adneScZpb3J3lLkj844i0EAAAeste//i9z5ZW3HNF17tixLe9+94sPadlrr70273vf+/Ke97wnSfL2t789j3rUozI/P58f/uEfzstf/vKceuqpy5b57ne/m+c///l5+9vfnje84Q256KKLcv755++37lprPve5z+WjH/1o3va2t+Uv//Iv87u/+7vZtm1bLrnkknzpS1/Kzp07H7R9e/bsya/92q9l9+7dOeGEE/KiF70of/7nf56tW7fmtttuy9VXX50kueOOO5Ikv/Vbv5Wvf/3r2bhx4+K0I+lge9TeneTfJxk2j09Mcketdb55vCfJSbMWLKWcV0rZXUrZvXfv3sNqLAAA8PD0xCc+Mc961rMWH//xH/9xdu7cmZ07d+a6667Ltddeu98yxxxzTF7ykpckSZ75zGfmxhtvnLnuf/7P//l+83zmM5/Jz/7szyZJTj/99DztaU970PZdfvnlOfvss/PoRz86GzZsyDnnnJO/+Zu/yZOe9KRcf/31ed3rXpePf/zjOeGEE5IkT3va0/LqV786H/zgBw/5S60fzAF71EopP5Hk1lrrFaWUF4wnz5i1zlq+1nphkguTZNeuXTPnAQAAjqxD7flaLccdd9zi/RtuuCG/8zu/k8997nPZsmVLXv3qV8/8zrGNGzcu3u/3+5mfn99vniTZtGnTfvPU+tCix0rzn3jiibnqqqvysY99LBdccEEuueSSXHjhhfn4xz+ev/7rv85HPvKR/OZv/mauueaa9Pv9h7TNB3MwPWrPTfKTpZQbMyoecnZGPWxbSinjoLc9ybeOWKsAAICj1p133pnjjz8+j3jEI3LzzTfn4x//+BHfxllnnZUPfehDSZKrr756Zo/dpGc/+9n51Kc+ldtvvz3z8/O5+OKL8/znPz979+5NrTWveMUr8ta3vjVf+MIXsrCwkD179uTss8/Ob//2b2fv3r353ve+d0Tbf8AetVrrm5O8OUmaHrU31lpfVUr50yQvzyi8vSbJR45oywAAgKPSzp07c+qpp+a0007LE57whDz3uc894tv4lV/5lfzcz/1cnvGMZ2Tnzp057bTTFoctzrJ9+/a87W1vywte8ILUWvPSl740P/7jP54vfOELee1rX5taa0opecc73pH5+fmcc845ueuuuzIcDvOmN70pxx9//BFtf3koXYITQe0nSilPyFJ5/i8meXWt9b4HW37Xrl119+7dh9FcAABgJdddd12e+tSntt2MTpifn8/8/Hzm5uZyww035Ed/9Edzww03ZDA46G8oO2yzjkcp5Ypa664DLfuQWllr/XSSTzf3v5bkjIeyPAAAwFq4++6788IXvjDz8/Optea//tf/uqYh7XA9fFoKAABwkLZs2ZIrrrii7WYcsofyhdcAAACsAUENAACgYwQ1AACAjln3Qe3ccy/Na17z/7XdDAAAgEXrPqjddNN3c+ONd7TdDAAAeNi7/fbbs2PHjuzYsSPbtm3LSSedtPj4/vvvP+j1XHTRRbnlllsWH//8z/98rr/++sNu3/z8fLZs2XLY61kL677q42DQy7598203AwAAHvZOPPHEXHnllUmSt7zlLdm8eXPe+MY3PuT1XHTRRdm5c2e2bduWJHnf+953RNv5cLDue9T6/V7m54dtNwMAAI5q73//+3PGGWdkx44d+df/+l9nOBxmfn4+5557bp7+9KfntNNOywUXXJA/+ZM/yZVXXpl/8S/+xWJP3FlnnZUrr7xysUfs/PPPz+mnn57nPOc5ufXWW5MkN9xwQ37oh34oZ5xxRn7913/9gD1nw+Ewb3jDG3Laaafl6U9/ej784Q8nSb75zW/mrLPOyo4dO3Laaaflsssum9nO1aZHbdDLwkJtuxkAAHBE/dWeu/Pte4/syLHHHjPIi7ZvfsjLXXPNNbn00ktz2WWXZTAY5LzzzsvFF1+cJz7xibntttty9dVXJ0nuuOOObNmyJb/7u7+b3/u938uOHTv2W9d3v/vdPP/5z8/b3/72vOENb8hFF12U888/P7/yK7+SN77xjXnFK16R3/u93ztgm/70T/801157bb70pS9l7969edaznpXnPe95+cAHPpCXvvSledOb3pSFhYXce++9ueKKK/Zr52pb9z1qg4EeNQAAWE1/9Vd/lc9//vPZtWtXduzYkb/+67/OV7/61TzpSU/K9ddfn9e97nX5+Mc/nhNOOOGA6zrmmGPykpe8JEnyzGc+MzfeeGOS5PLLL8/P/MzPJEnOOeecA67nM5/5TM4555z0+/1s27YtZ511Vnbv3p1nPetZee9735u3vvWtueaaa7J58+ZDaufhWvc9av1+EdQAADjqHErP12qpteYXfuEX8h/+w3/Y73dXXXVVPvaxj+WCCy7IJZdckgsvvPBB17Vx48bF+/1+P/Pzh9ZrWOvsUXVnn312Pv3pT+e///f/nle96lV585vfnFe96lUPuZ2HS4/aoJeFBUENAABWy4te9KJ86EMfym233ZZkVB3yG9/4Rvbu3Ztaa17xilfkrW99a77whS8kSY4//vjcddddD2kbZ5xxRi699NIkycUXX3zA+Z/3vOfl4osvzsLCQr797W/nb//2b7Nr1658/etfz7Zt23LeeeflX/7Lf5kvfvGLK7ZzNelRU0wEAABW1dOf/vT8xm/8Rl70ohdlOBxmw4YNec973pN+v5/Xvva1qbWmlJJ3vOMdSUbl+P/Vv/pXOeaYY/K5z33uoLZxwQUX5Nxzz8073vGO/NiP/dgBhye+/OUvz2c/+9mcfvrpKaXkne98Zx7zmMfkoosuyjvf+c5s2LAhmzdvzgc+8IHcdNNNM9u5mspKXX6rYdeuXXX37t1rtr2Dce65l+ayy27KV7/6b9tuCgAAHJbrrrsuT33qU9tuRivuueeeHHvssSml5AMf+EAuvfTSXHLJJa22adbxKKVcUWvddaBl132PmmIiAADw8Pf5z38+r3/96zMcDvPIRz7yYf/da+s+qCkmAgAAD38veMELFr9s+2igmIhiIgAAHEXW8tImVna4x2HdBzU9agAAHC3m5uZy++23C2stq7Xm9ttvz9zc3CGvY90PfRz1qHkhAwDw8Ld9+/bs2bMne/fubbsp697c3Fy2b99+yMsLaoqJAABwlNiwYUMe//jHt90MjgBDH32PGgAA0DHrPqgpJgIAAHTNug9qiokAAABds+6D2mDQS63JcKigCAAA0A2C2mC0Cwx/BAAAumLdB7V+f7QLDH8EAAC6Yt0HtaUeNUMfAQCAblj3Qa3fL0n0qAEAAN2x7oOaa9QAAICuEdQGrlEDAAC6Zd0HNcVEAACArln3QU0xEQAAoGvWfVBTTAQAAOiadR/UXKMGAAB0jaCm6iMAANAx6z6oKSYCAAB0zboPaoqJAAAAXSOouUYNAADomHUf1FR9BAAAumbdBzXFRAAAgK5Z90FNMREAAKBr1n1QU0wEAADoGkFNMREAAKBj1n1QU0wEAADomnUf1BQTAQAAumbdBzXFRAAAgK5Z90FNMREAAKBrBDXFRAAAgI5Z90FNMREAAKBr1n1QU0wEAADomnUf1BQTAQAAumbdBzXFRAAAgK4R1BQTAQAAOmbdBzXFRAAAgK45YFArpcyVUj5XSvlSKeXLpZS3NtP/qJTyD6WUK5ufHavf3CNPMREAAKBrBgcxz31Jzq613l1K2ZDkM6WUjzW/+79qrR9eveatPsVEAACArjlgUKu11iR3Nw83ND9HTeUNxUQAAICuOahr1Eop/VLKlUluTfKJWuvlza/+YynlqlLKu0opm1atlatIMREAAKBrDiqo1VoXaq07kmxPckYp5bQkb07yA0meleRRSd40a9lSynmllN2llN179+49Qs0+chQTAQAAuuYhVX2std6R5NNJXlxrvbmO3JfkfUnOWGGZC2utu2qtu7Zu3XrYDT7SSinp9YpiIgAAQGccTNXHraWULc39Y5K8KMnflVIe10wrSX4qyTWr2dDV1O8XPWoAAEBnHEzVx8cleX8ppZ9RsPtQrfXPSyn/s5SyNUlJcmWSX1rFdq6qwaCnmAgAANAZB1P18aokPzhj+tmr0qIWDAY9PWoAAEBnPKRr1I5W/b6gBgAAdIeglvHQR0ENAADoBkEthj4CAADdIqhlVPVRMREAAKArBLXoUQMAALpFUItiIgAAQLcIavE9agAAQLcIajH0EQAA6BZBLaNiIoIaAADQFYJafI8aAADQLYJaFBMBAAC6RVCLYiIAAEC3CGpRTAQAAOgWQS2KiQAAAN0iqEUxEQAAoFsEtSgmAgAAdIugFsVEAACAbhHUopgIAADQLYJaFBMBAAC6RVCLYiIAAEC3CGpRTAQAAOgWQS2KiQAAAN0iqEUxEQAAoFsEtSgmAgAAdIugFsVEAACAbhHUokcNAADoFkEtiokAAADdIqhFMREAAKBbBLX4HjUAAKBbBLUoJgIAAHSLoBZDHwEAgG4R1DKq+lhrMhwqKAIAALRPUMuoRy2J4Y8AAEAnCGoZFRNJYvgjAADQCYJaJnvUDH0EAADaJ6hlKajpUQMAALpAUMuomEjiGjUAAKAbBLXoUQMAALpFUItiIgAAQLcIalFMBAAA6BZBLYY+AgAA3SKoRTERAACgWwS16FEDAAC6RVCLYiIAAEC3CGpRTAQAAOgWQS2GPgIAAN0iqGWpmIigBgAAdIGglsmhj4IaAADQPkEtiokAAADdIqhFMREAAKBbBLUoJgIAAHSLoBbFRAAAgG4R1KKYCAAA0C2CWhQTAQAAuuWAQa2UMldK+Vwp5UullC+XUt7aTH98KeXyUsoNpZQ/KaVsXP3mrg7FRAAAgC45mB61+5KcXWs9PcmOJC8upTw7yTuSvKvW+uQk/5jktavXzNWlmAgAANAlBwxqdeTu5uGG5qcmOTvJh5vp70/yU6vSwjWgmAgAANAlB3WNWimlX0q5MsmtST6R5KtJ7qi1zjez7Ely0uo0cfUpJgIAAHTJQQW1WutCrXVHku1Jzkjy1FmzzVq2lHJeKWV3KWX33r17D72lq0gxEQAAoEseUtXHWusdST6d5NlJtpRSBs2vtif51grLXFhr3VVr3bV169bDaeuqUUwEAADokoOp+ri1lLKluX9MkhcluS7Jp5K8vJntNUk+slqNXG2KiQAAAF0yOPAseVyS95dS+hkFuw/VWv+8lHJtkotLKb+Z5ItJ/nAV27mqFBMBAAC65IBBrdZ6VZIfnDH9axldr/awp5gIAADQJQ/pGrWjlaGPAABAlwhqWar6qJgIAADQBYJa9KgBAADdIqhFMREAAKBbBLUkpZT0ekUxEQAAoBMEtcZg0NOjBgAAdIKg1uj3i2IiAABAJwhqDT1qAABAVwhqjX5fUAMAALpBUGsMBj3FRAAAgE4Q1BqGPgIAAF0hqDUUEwEAALpCUGvoUQMAALpCUGsoJgIAAHSFoNYYFRMx9BEAAGifoNYw9BEAAOgKQa0xKiYiqAEAAO0T1Bp61AAAgK4Q1BqKiQAAAF0hqDUUEwEAALpCUGsY+ggAAHSFoNbo94ugBgAAdIKg1hgNfRTUAACA9glqDcVEAACArhDUGoqJAAAAXSGoNRQTAQAAukJQaygmAgAAdIWg1lBMBAAA6ApBrWHoIwAA0BWCWqPfV0wEAADoBkGtoUcNAADoCkGtoZgIAADQFYJaQzERAACgKwS1hqGPAABAVwhqjX6/KCYCAAB0gqDW0KMGAAB0haDW6PcFNQAAoBsEtYZiIgAAQFcIag1DHwEAgK4Q1Br9fkmtyXCooAgAANAuQa0xGIx2heGPAABA2wS1Rr8/2hWGPwIAAG0T1BpLPWqGPgIAAO0S1BrjoKZHDQAAaJug1uj3SxLXqAEAAO0T1Bp61AAAgK4Q1BqKiQAAAF0hqDUUEwEAALpCUGsY+ggAAHSFoNZQTAQAAOgKQa2hRw0AAOgKQa2hmAgAANAVglpDMREAAKArBLWGoY8AAEBXHDColVJOLqV8qpRyXSnly6WU1zXT31JK+WYp5crm58dWv7mrRzERAACgKwYHMc98kn9Xa/1CKeX4JFeUUj7R/O5dtdb/tHrNWzt61AAAgK44YFCrtd6c5Obm/l2llOuSnLTaDVtrghoAANAVD+katVLKKUl+MMnlzaR/U0q5qpRyUSnlkUe4bWtqXPVRMREAAKBtBx3USimbk1yS5PW11juT/EGSJybZkVGP239eYbnzSim7Sym79+7dewSavDr0qAEAAF1xUEGtlLIho5D2wVrrnyVJrfXbtdaFWuswyX9LcsasZWutF9Zad9Vad23duvVItfuIGxcTEdQAAIC2HUzVx5LkD5NcV2t958T0x03M9tNJrjnyzVs7S9+jJqgBAADtOpiqj89Ncm6Sq0spVzbTfjXJK0spO5LUJDcm+cVVaeEaMfQRAADoioOp+viZJGXGr/7iyDenPYqJAAAAXfGQqj4ezfSoAQAAXSGoNRQTAQAAukJQaygmAgAAdIWg1jD0EQAA6ApBraGYCAAA0BWCWkOPGgAA0BWCWkMxEQAAoCsEtYZiIgAAQFcIag1DHwEAgK4Q1BqKiQAAAF0hqDX0qAEAAF0hqDUUEwEAALpCUGuUUtLrFcVEAACA1glqEwaDnh41AACgdYLahH6/KCYCAAC0TlCboEcNAADoAkFtQr8vqAEAAO0T1CYMBj3FRAAAgNYJahMMfQQAALpAUJugmAgAANAFgtoEPWoAAEAXCGoTFBMBAAC6QFCbMComYugjAADQLkFtgqGPAABAFwhqE0bFRAQ1AACgXYLaBD1qAABAFwhqEwQ1AACgCwS1Cf2+YiIAAED7BLUJetQAAIAuENQmKCYCAAB0gaA2QY8aAADQBYLaBEENAADoAkFtgmIiAABAFwhqE/SoAQAAXSCoTVBMBAAA6AJBbYIeNQAAoAsEtQmCGgAA0AWC2gTFRAAAgC4Q1CboUQMAALpAUJvQ7xdBDQAAaJ2gNmEw6Kn6CAAAtE5Qm2DoIwAA0AWC2oTR96gpJgIAALRLUJugRw0AAOgCQW1Cvy+oAQAA7RPUJigmAgAAdIGgNsHQRwAAoAsEtQn9fkmtyXCooAgAANAeQW3CYDDaHYY/AgAAbRLUJvT7o91h+CMAANAmQW3CUo+aoY8AAEB7BLUJ46CmRw0AAGiToDah3y9JXKMGAAC0S1CboEcNAADoAkFtgqAGAAB0wQGDWinl5FLKp0op15VSvlxKeV0z/VGllE+UUm5obh+5+s1dXeOqj4qJAAAAbTqYHrX5JP+u1vrUJM9O8sullFOTnJ/kk7XWJyf5ZPP4YU2PGgAA0AUHDGq11ptrrV9o7t+V5LokJyV5WZL3N7O9P8lPrVYj14piIgAAQBc8pGvUSimnJPnBJJcneWyt9eZkFOaSPGaFZc4rpewupezeu3fv4bV2lelRAwAAuuCgg1opZXOSS5K8vtZ658EuV2u9sNa6q9a6a+vWrYfSxjUjqAEAAF1wUEGtlLIho5D2wVrrnzWTv11KeVzz+8cluXV1mrh2FBMBAAC64GCqPpYkf5jkulrrOyd+9dEkr2nuvybJR45889aWHjUAAKALBgcxz3OTnJvk6lLKlc20X03y9iQfKqW8Nsk3krxidZq4dhQTAQAAuuCAQa3W+pkkZYVfv/DINqddetQAAIAueEhVH492ghoAANAFgtoExUQAAIAuENQm6FEDAAC6QFCboJgIAADQBYLaBD1qAABAFwhqEwQ1AACgCwS1CYqJAAAAXSCoTdCjBgAAdIGgNkExEQAAoAsEtQl61AAAgC4Q1CYIagAAQBcIahMUEwEAALpAUJugRw0AAOgCQW3CuJiIoAYAALRJUJsw7lFT9REAAGiToDbB0EcAAKALBLUJiokAAABdIKhN0KMGAAB0gaA2QTERAACgCwS1CaWU9HpFMREAAKBVgtqUwaCnRw0AAGiVoDal3y+KiQAAAK0S1KboUQMAANomqE0R1AAAgLYJalP6/Z5iIgAAQKsEtSl61AAAgLYJalMUEwEAANomqE3RowYAALRNUJsiqAEAAG0T1KaMiokY+ggAALRHUJuiRw0AAGiboDZlVExEUAMAANojqE3RowYAALRNUJsiqAEAAG0T1KYoJgIAALRNUJuiRw0AAGiboDZFMREAAKBtgtoUPWoAAEDbBLUpghoAANA2QW2KYiIAAEDbBLUpetQAAIC2CWpTFBMBAADaJqhN0aMGAAC0TVCbIqgBAABtE9SmKCYCAAC0TVCbokcNAABom6A2RTERAACgbYLaFD1qAABA2wS1KYIaAADQNkFtymjoo2IiAABAewS1KXrUAACAtglqUwQ1AACgbYLalNH3qAlqAABAewS1KXrUAACAth0wqJVSLiql3FpKuWZi2ltKKd8spVzZ/PzY6jZz7fT7JbUmw6GCIgAAQDsOpkftj5K8eMb0d9VadzQ/f3Fkm9WewWC0Swx/BAAA2nLAoFZr/Zsk31mDtnTCOKgZ/ggAALTlcK5R+zellKuaoZGPXGmmUsp5pZTdpZTde/fuPYzNrY1+f9yjZugjAADQjkMNan+Q5IlJdiS5Ocl/XmnGWuuFtdZdtdZdW7duPcTNrR09agAAQNsOKajVWr9da12otQ6T/LckZxzZZrWn3y9JXKMGAAC055CCWinlcRMPfzrJNSvN+3CjRw0AAGjb4EAzlFL+OMkLkjy6lLInyW8keUEpZUeSmuTGJL+4im1cU4IaAADQtgMGtVrrK2dM/sNVaEsnKCYCAAC07XCqPh6V9KgBAABtE9SmKCYCAAC0TVCbokcNAABom6A2RVADAADaJqhNUUwEAABom6A2RY8aAADQNkFtimIiAABA2wS1KXrUAACAtglqUwQ1AACgbYLaFMVEAACAtglqU/SoAQAAbRPUpigmAgAAtE1Qm6JHDQAAaJugNkVQAwAA2iaoTVFMBAAAaJugNkWPGgAA0DZBbco4qCkmAgAAtEVQmzKu+qhHDQAAaIugNsXQRwAAoG2C2hTFRAAAgLYJalP0qAEAAG0T1KYoJgIAALRNUJuimAgAANA2QW2KoY8AAEDbBLUpiokAAABtE9Sm6FEDAADaJqhNcY0aAADQNkFtSiklvV5R9REAAGiNoDbDYNDTowYAALRGUJuh3y+KiQAAAK0R1GbQowYAALRJUJtBUAMAANokqM3Q7/cUEwEAAFojqM2gRw0AAGiToDaDYiIAAECbBLUZ9KgBAABtEtRmENQAAIA2CWozjIqJGPoIAAC0Q1CbQY8aAADQJkFthlExEUENAABoh6A2gx41AACgTYLaDIIaAADQJkFtBsVEAACANglqM+hRAwAA2iSozTAY9BQTAQAAWiOozdDvFz1qAABAawS1GQx9BAAA2iSozaCYCAAA0CZBbQY9agAAQJsEtRkUEwEAANokqM2gmAgAANAmQW0GQx8BAIA2CWozKCYCAAC0SVCbQY8aAADQpgMGtVLKRaWUW0sp10xMe1Qp5ROllBua20eubjPX1mBQFBMBAABaczA9an+U5MVT085P8sla65OTfLJ5fNTo9/WoAQAA7TlgUKu1/k2S70xNflmS9zf335/kp45wu1pl6CMAANCmQ71G7bG11puTpLl9zEozllLOK6XsLqXs3rt37yFubm31+0UxEQAAoDWrXkyk1nphrXVXrXXX1q1bV3tzR4QeNQAAoE2HGtS+XUp5XJI0t7ceuSa1bzDoKSYCAAC05lCD2keTvKa5/5okHzkyzekGxUQAAIA2HUx5/j9O8r+TPKWUsqeU8tokb0/yI6WUG5L8SPP4qGHoIwAA0KbBgWaotb5yhV+98Ai3pTP6/ZJak+GwptcrbTcHAABYZ1a9mMjD0WAw2i2uUwMAANogqM0wDmqGPwIAAG0Q1Ga4bBy3AAAaKElEQVTo98c9ar5LDQAAWHuC2gx61AAAgDYJajP0+6MCIq5RAwAA2iCozaBHDQAAaJOgNoOgBgAAtGndB7XLbvle/vct31s2TTERAACgTes+qH39rgfylTvvXzZNjxoAANCmdR/U5gYl++aX95wpJgIAALRJUOuX7JsKZHrUAACANglq/V72LdTUutSrJqgBAABtEtT6JQs1mRz9qJgIAADQJkFtMLoebd9E75keNQAAoE2CWtN7tm9h/6GPiokAAABtENSaCo+TQW1c9VGPGgAA0AZBbTz0ccHQRwAAoBsEtfHQx/nJHjXFRAAAgPYIajOGPupRAwAA2rTug9qm/spDHxUTAQAA2rDug1qvlGzqF8VEAACAzlj3QS0ZDX+cvEbN0EcAAKBNglqaoDYxzFExEQAAoE2CWkaVHxUTAQAAukJQy+i71GYFNcVEAACANghqGV+jNjn0UTERAACgPYJaDH0EAAC6RVDLqEdtoSYPDEdhTTERAACgTYJaRteoJUtfeq1HDQAAaJOgltHQxySL36WmmAgAANAmQS2joY9Jct/CeOijYiIAAEB7BLUsBbVxQRFDHwEAgDYJaknmmmA2vkZNMREAAKBNglometTm9agBAADtE9SSbJoa+ji+Rk0xEQAAoA2CWpJeKdnUK4tDH0sp6fWKHjUAAKAVglpj06As9qglo+GPghoAANAGQa0x1y+L16glo+GPiokAAABtENQac/3e4tDHRI8aAADQHkGtMdc39BEAAOgGQa0xN3WNWr/fU/URAABohaDWmOv3sm/e0EcAAKB9glpjrl8yX5P54dKXXismAgAAtEFQa8zN+NJrPWoAAEAbBLXGXH+0K8aVHw19BAAA2iKoNeYGTY/a/LhHzdBHAACgHYJaY3roox41AACgLYJaY9bQR+X5AQCANghqDcVEAACArhDUGpumrlEz9BEAAGiLoNbol5KNvbI49FExEQAAoC2C2oS5flFMBAAAaJ2gNmHTVFBTTAQAAGiDoDZhblCyb3489FExEQAAoB2Dw1m4lHJjkruSLCSZr7XuOhKNastcv5c77ltIYugjAADQnsMKao0frrXedgTW07rJa9QUEwEAANpi6OOEUVBb+sJrPWoAAEAbDjeo1ST/o5RyRSnlvFkzlFLOK6XsLqXs3rt372FubnXNDXp5YJgsDKtiIgAAQGsON6g9t9a6M8lLkvxyKeV50zPUWi+ste6qte7aunXrYW5udc31my+9XqiKiQAAAK05rKBWa/1Wc3trkkuTnHEkGtWWpaA2NPQRAABozSEHtVLKcaWU48f3k/xokmuOVMPaMNcf7Y5Rj5piIgAAQDsOp+rjY5NcWkoZr+f/rbX+5RFpVUvmBk2P2nzVowYAALTmkINarfVrSU4/gm1p3fKhj0UxEQAAoBXK80+YHvqoRw0AAGiDoDZhcejjgqGPAABAewS1Cf1SsqGX7Jsfpt8viokAAACtENSmzPV7etQAAIBWCWpT5vplMagpJgIAALRBUJsyNyjZtzBUTAQAAGiNoDZlrt/zPWoAAECrBLUpk0Mfa02GQwVFAACAtSWoTZnrl9y3UNNvvvzadWoAAMBaE9SmzA16uX9Y098w2jVK9AMAAGtNUJsy1/Sk9TdtSBLXqQEAAGtOUJuyGNTmBkkENQAAYO0JalPm+qNd0t80CmquUQMAANaaoDZlbjDqUSsb+0n0qAEAAGtPUJsyHvrY2ySoAQAA7RDUpoyHPmbDeOijqo8AAMDaEtSmbGp61EpTnv/++xfabA4AALAOCWpTBr2SQUmOf9SxSZLrrtvbcosAAID1RlCbYW7Qy5atx2Yw6OWyy25quzkAAMA6I6jNMNcvmU/Jzp2Py2WX7Wm7OQAAwDojqM0w1y/Zt1Bz5pnb87nPfTMPPOA6NQAAYO0IajPM9XvZtzDMmWeenH375nPllbe03SQAAGAdEdRmmBuU7Juvec5zTk4S16kBAABrSlCbYTz0cfv2R+T7vu8E16kBAABrSlCbYa7fy/3DmmGtOfPMk/WoAQAAa0pQm2Gu+dLrcUGRPXvuzE03fbflVgEAAOuFoDbD3KAJavOjHrXEdWoAAMDaEdRmmOuPdsu+hWGe8YzH5thjNwhqAADAmhHUZpgc+rhhQz9nnHGSgiIAAMCaEdRmmAxqSXLmmdvzxS/enHvuub/NZgEAAOuEoDbD3KAZ+jg/TJKceebJWVio2b37W202CwAAWCcEtRmme9Se/eztSRQUAQAA1oagNsOgVzIoS0HtxBOPzQ/8wKNdpwYAAKwJQW0Fc/1e9i0MFx+feeb2XHbZTam1ttgqAABgPRDUVjA3KNk3vxTKzjzz5HznO/fm7//+9hZbBQAArAeC2grm+mVx6GMSX3wNAACsGUFtBZv6ZdnQx6c85dHZsmVOUAMAAFadoLaC0TVqSz1qvV7Jc56zXUERAABg1QlqK5gblNw3v7xwyJlnnpxrr92bf/zHe1tqFQAAsB4IaiuY65fcN6wZ1v2vU/vsZ/WqAQAAq0dQW8Fcf7Rr7psY/njGGSel1yuuUwMAAFaVoLaC4zeMds3uvfcufnfa5s0bc/rpj3WdGgAAsKoEtRV8/5aNOe1Rm/K3t9yb/7HnnsUhkGeeeXIuv3xP5ueHB1gDAADAoRHUVtArJT/+fZvz7Mccky/eti8fufGuzA9rzjzz5NxzzwO5+upvt91EAADgKDVouwFdVkrJC046Lsdt6OWT37wn35v/bp717O1Jkj/7s+uyY8e2lFJabiUAAHC00aN2EJ71mGPy0n+6Od+8Zz7/677kJT/9A/nN3/xfednLLs6ePXe23TwAAOAoI6gdpKc9ai6veMIjcsf9C/mJt/1Ifuu9P5m/+quv5dRTfz/vec/uDIf1wCsBAAA4CILaQ/D4R2zMOU8+IfO1ZmHnyfmt//2LecWb/ln+/a9/Ki94wR/l+utva7uJAADAUaDUunY9Qbt27aq7d+9es+2tlvsXav7ujvty1e37suee+aTWfPXyPdn9kWvzY7sel1e/6ul56lO3tt1MAACgY0opV9Radx1wPkHt8Hxn30Ku/s6+fGnvvfneMLnvew/kW3+3N/fcfGeecOIxeeGubflnz3xcej2dlwAAsN4JamtsWGv+4c4HctXNd+crt34v989tSH9DP0my7677kjv3Zetxg5zymOPypH9yfB4518+Wjf1s7KsaCQAA68XBBjXl+Y+QXil54gkb88QTHpX8wKOyUGu++u178snPfyvf/vb3Mn/sxtRHzOWu+5Orb7xrabn5hWwelGyZ25BHHjfI5g29HDfo5bjm9phByTH9XuYGJT1fBQAAAOuCoLZK+qXk+7dtzve/9PuTJPffv5Brr92bz1+5J1/+2h35xm335s75YU7YdnxOeOxx2XzicXnEo4/NcY88JqU3O5BtKMkxg16OHfSysV9GP73mp7m/oZds6JXlP/3R9EEZPe73kg2lZNAr6Zf4LjgAAOgYQW2NbNzYz44d27Jjx7bFaQ88sJDrrrstN9xwe2666Y7c9Pmv5+/33JVb79iXO773QPbVZO74TTn2hLkc84jR7bEnzOURJx6b407YlE3HbcymYzdkw9yG9Df102uGWj5Ug5L0e2XitmTQG4XNfhn1FvZKpu6XlCS9Mv4ZTe9l9LvxtP7U70uSUpKS0fJpllm2jpL00sy/uExJL5OPl9ZRmnUsTmvmydT8veZ3vcXtLn9csrQtAABo02EFtVLKi5P8TpJ+kvfWWt9+RFq1TmzY0M8znvHYPOMZj535+/n5YW677Xu5+ea7csstd+eWW+7OzTffnVuuuyW3/+O+3HHH8p/v3nlf7l8YZuMxG7JhbrDsduPcIINNg2zY1F92u3FukLljN2TTsRsyd8yGxXk3bhpkw1w//Q399Ae99Aej296gpNfvpfTKqOdvfFua+83tYjp6mCqTt2X5tP3uL/5+IjhOhc1xJ+lKl4ROBtlxaC1JpmevWT6xTs0xDqpL61oK1Cs+12XBtkwE1qn5ZrVlfH/iwbL1TawzTTsmQ/PkOlda3+R6c4B5ZrVh8vFkeyanLc247Ca1jtpVJ+/Xuuw5LVtP2W9Vzf0y8TrJsu1nev2L9+v4dMZ++3Q8XybmXf40lpab3Ob0tEnj7Y7vLy439frY/7ll8UTHSqbXPb42enI7i+ub2Mb0MRqfjBk/3/E+m1zXpOn9O6yjJYfNcsM62sfjE0SL75mpY5Pp/TLxXp08OTS9DyZfs0uvn6VtP9gV4vsfr6WTW5O/n76/bH/U5ftl1hYn2z+5D5avoy47his9x2T/19D0c1raV6M7tdYMazLM/sdovJ7J10utoxOKkycPx7epyTA1C3U030Kz7jTPbXwScfKk4+RxGaY2t0vHc/SZtfxE4XBi3Yv3m/n7zetncRvNcpPHY/I5zToeiztrBZNtGX/Gl7L0HIZ1vC+XntP08xi/dmeZfH9NHsvpvz/Ll1m6nT5eyfLjvuzzeYWnO/k3aPJvazJ+/y49z/H76UGat/+2l/1NmL2dyUNUp9Y1+ZzG05bvg6XH49f0+LVVZ7wu+73J12dZ3P6wedGM3x8zn9uKf3ey/449SEvPqyw7RrUm87XmgWHN/LBmvmZ0O6zpT4zUWjz53zynB91O2X/a0mf28s/LmpWP20o2b+jlscc+fPulDrnlpZR+kt9P8iNJ9iT5fCnlo7XWa49U49a7waCXbds2Z9u2zQe9zMLCMHfffX/uuuv+3HXXfctu9+2bz733PtDcju7fe+/86PHtd+fee+fzvXvnc3sz/d57H8h99y1k3775ZT/33vtA5ueHWViomZ8frvhl36VXmnDXS3/QhLtSmtssC3z9fklv0E+vX0bz90fLlV7zx6Xf22+Z0bqSXq+XXr9kMOilv6GXfvO41++l32/a0G/W2S/pD8rE42beZp1Lt6PppflEKKXZ3vh+84/C6Hb5siv+NJ9Iy/5QNOtNs67J55ZeWfZHYOY/aBOf0IvrXOyKHO2fjLexbMbx3Wbbk/9BZel5Ly6wwh+C/abNWqZMP27+QRvff5D1HoyZy43/0E5NqFPTZ75yp/67XvY0ptQV7j+cT1IAwNHiqVs25mWPf0TbzThkhxMxz0jylVrr15KklHJxkpclEdRa1O/3csIJcznhhLk122atdTG0PfDAQh54YJj77pvP/fcvLP7cd99CFhaGywLe+Gc8ffrngQdGIXD8s7AwbG5H91daz9L808suZOH+muG+pd+N1zk/bM6kTm2v1ubs1wq/n2zPePriWci6dH80vU4tP1puNO/S/OOzkZPbnF52cv7x76fXMXlLu8ZBuDThezKU1/HxGx/X4ej+suUmbktplkmSieVmbm98myydDBj3WDVBvjanKUevlbp4fzzP4gmF3tL2s7iOLNvGg73Uxs+rNvdnb2dpXdPbm3y8+LqevG32x/KdsGS4UDNcGKYOJ2/r4kmWXnMyafF+00WxuJ+nVl16vf1P0Ezs49FzWNp3Gb93J38e5M1ZJo7feKNL+6PpQSqjz/zF7S7uguWvizqs+32e1GFd3K+9XmlObk2MmBgf9/HzzdLjWft43KOTJKU57z15gqnXW3otTb6m6kLNcDhMhmlum8+5ZnpdSIZ1mIX5pX02Pvk3edsb9EavqcnupJrUhTrq4drQnJibXKZfRp/D88MMF4ZZmB/9zD8wTEppRpM08/fL4sm+2ryWhuO/N/PD0Xb6Sb/fH50wHIy3Nzrxt2y/jV/3iztvNGn83lzW4zzx2qujmRZPJI5PgI7bNXr+w8XbOhztj8kTcYuvx/FJvcUmLL2DF99jw6YnY/JzZsZ7Yb+nNvG+nOw2H71Xxidgm/fQ5HnApS6SpROj4xOWZfQ6XbahiS67kqW/mYufpXW4uF9H2x6d7B293ifeNxMnTBdfo4u9icu7FRffs1MnP8f7bFb34+JnerNPF9/7tab0eumNXy+D/uhE8qC/uM9nfWb0elMnlzN67062Z/GE6wqmX2uTu3S000brqIufgc16a01dqKkLw2Rh9Lqv88OUYR13D6b0e6Nju3h/8rhOnLPtlcVtLH5+THZnTnbpThzrUY9knXgJNJ83zXHu9dLcjra96dRHJ7/4zJV3RscdTlA7KclNE4/3JPmhw2sOD0ellAwGox6tubmHb/fy0W4ytE0HuaUAODsQjpZZOQgeyu104Jw1bel/1KVgMNmWyfnHPbvTAfVAYfVgQu70/fF2Vno8a79N9siOn8tk6Jg+BrPWcaDjMGv9k9tZqZ0rPd+Vtn8o+/LB9tnBrGv6OMyaf3qdk9PK+B/FyZ7xqdfTrP2z0v2Dea7T0/Zv84M//2U95tP/o8543zyYAz3/6f01/bqc/HmwfwAf7Lg/2HOdbsdkO3u9st/reaX1zDqpNus1Md5ev18W//Gd/Jlc3+R6JkeQTK/3QK+DWSfVlv2/P+N4z3rOs4794rqT0VDVUpJ+UntLr/+ldTXrXtbG5ScNp0eQlEFvZjtm7YuVjs1++2U4XGHelde/0r4cvS73f51MXnawMPX5utJooANZ6e/SrLZPH+NZz3XWa2fW+3QyXM1+Xz7IhqbaNH680t+lWa+/cZh6sO1P7//pv3Oz/i7O2qcP9vk/6z07XufkCfTxCfVHP8z/LT2c5s96Rez3qi+lnJfkvCT5vu/7vsPYHHA4Jj98Z799AQDoit5hLLsnyckTj7cn+db0TLXWC2utu2qtu7Zu3XoYmwMAAFgfDieofT7Jk0spjy+lbEzys0k+emSaBQAAsH4d8tDHWut8KeXfJPl4RuX5L6q1fvmItQwAAGCdOqxL7Gqtf5HkL45QWwAAAMjhDX0EAABgFQhqAAAAHSOoAQAAdIygBgAA0DGCGgAAQMcIagAAAB0jqAEAAHSMoAYAANAxghoAAEDHCGoAAAAdI6gBAAB0jKAGAADQMYIaAABAxwhqAAAAHSOoAQAAdIygBgAA0DGCGgAAQMcIagAAAB0jqAEAAHRMqbWu3cZK2Zvk62u2wYP36CS3td0IWuP4r2+O//rm+K9vjv/65divb20f/39aa916oJnWNKh1VSlld611V9vtoB2O//rm+K9vjv/65vivX479+vZwOf6GPgIAAHSMoAYAANAxgtrIhW03gFY5/uub47++Of7rm+O/fjn269vD4vi7Rg0AAKBj9KgBAAB0zLoOaqWUF5dSri+lfKWUcn7b7WF1lVJOLqV8qpRyXSnly6WU1zXTH1VK+UQp5Ybm9pFtt5XVU0rpl1K+WEr58+bx40splzfH/09KKRvbbiOro5SypZTy4VLK3zWfA8/x/l8/Sin/Z/PZf00p5Y9LKXPe/0evUspFpZRbSynXTEyb+X4vIxc0/w9eVUrZ2V7LORJWOP6/3Xz+X1VKubSUsmXid29ujv/1pZT/o51W72/dBrVSSj/J7yd5SZJTk7yylHJqu61ilc0n+Xe11qcmeXaSX26O+flJPllrfXKSTzaPOXq9Lsl1E4/fkeRdzfH/xySvbaVVrIXfSfKXtdYfSHJ6Rq8D7/91oJRyUpJ/m2RXrfW0JP0kPxvv/6PZHyV58dS0ld7vL0ny5ObnvCR/sEZtZPX8UfY//p9Iclqt9RlJ/j7Jm5Ok+V/wZ5M8rVnmvzQ5oXXrNqglOSPJV2qtX6u13p/k4iQva7lNrKJa68211i809+/K6J+0kzI67u9vZnt/kp9qp4WstlLK9iQ/nuS9zeOS5OwkH25mcfyPUqWURyR5XpI/TJJa6/211jvi/b+eDJIcU0oZJDk2yc3x/j9q1Vr/Jsl3piav9H5/WZL/p458NsmWUsrj1qalrIZZx7/W+j9qrfPNw88m2d7cf1mSi2ut99Va/yHJVzLKCa1bz0HtpCQ3TTze00xjHSilnJLkB5NcnuSxtdabk1GYS/KY9lrGKnt3kn+fZNg8PjHJHRMf3D4Hjl5PSLI3yfuaoa/vLaUcF+//daHW+s0k/ynJNzIKaN9NckW8/9ebld7v/idcf34hycea+509/us5qJUZ05TAXAdKKZuTXJLk9bXWO9tuD2ujlPITSW6ttV4xOXnGrD4Hjk6DJDuT/EGt9QeT3BPDHNeN5lqklyV5fJJ/kuS4jIa7TfP+X5/8LVhHSin/d0aXw3xwPGnGbJ04/us5qO1JcvLE4+1JvtVSW1gjpZQNGYW0D9Za/6yZ/O3xEIfm9ta22seqem6Snyyl3JjRUOezM+ph29IMhUp8DhzN9iTZU2u9vHn84YyCm/f/+vCiJP9Qa91ba30gyZ8lOTPe/+vNSu93/xOuE6WU1yT5iSSvqkvfUdbZ47+eg9rnkzy5qfi0MaOLCD/acptYRc31SH+Y5Lpa6zsnfvXRJK9p7r8myUfWum2svlrrm2ut22utp2T0fv+ftdZXJflUkpc3szn+R6la6y1JbiqlPKWZ9MIk18b7f734RpJnl1KObf4WjI+/9//6stL7/aNJfq6p/vjs5P9v7w5VIoiiOIx/B8HtYhb0CXwAw0YRsYkGy4LBBxBEDWLwDcxWwSQWH8AiImyw2w0Gy4IgHMMdURZtLnPZ+X51LsOB4TL879xzh7evLZKaHhGxChwAG5k5+nHpBtiOiF5ELFIOlXloo8Zxnf7hdUSsUVbUZ4CLzDxruSRNUESsAHfAE989SkeUPrUrYIHyMt/MzPEGZE2RiOgD+5m5HhFLlC9sc8AQ2MnM9zbr02RExDLlIJlZ4BkYUBYsnf8dEBGnwBZly9MQ2KX0oTj/p1BEXAJ9YB54AU6Aa36Z7014P6ec+DcCBpn52Ebd+h9/PP9DoAe8NsPuM3OvGX9M6Vv7oLTG3I7fsw2dDmqSJEmSVKMub32UJEmSpCoZ1CRJkiSpMgY1SZIkSaqMQU2SJEmSKmNQkyRJkqTKGNQkSZIkqTIGNUmSJEmqjEFNkiRJkirzCf3KpuOA+7yJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save training data loss and validation data loss as variables to plot:\n",
    "train_loss = history.history['loss']     # 'loss' = mean squared error of training data\n",
    "test_loss = history.history['val_loss']  # 'val_loss' = mean squared error of validation data\n",
    "\n",
    "# Plot training and testing loss for the FFNN model:\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(train_loss, label='Training loss', color='navy')\n",
    "plt.plot(test_loss, label='Testing loss', color='skyblue')\n",
    "plt.legend();\n",
    "\n",
    "# Save figure as a PNG file:\n",
    "plt.savefig('../../images/FFNN_fantasy_training_vs_testing_loss_function.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Assign predicted fantasy points to validation data as a new column:\n",
    "X_test['Predicted_FP'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Assign true fantasy points to validation data as a new column:\n",
    "X_test['FantasyPoints'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Week</th>\n",
       "      <th>PassingYards</th>\n",
       "      <th>PassingTouchdowns</th>\n",
       "      <th>PassingInterceptions</th>\n",
       "      <th>RushingYards</th>\n",
       "      <th>RushingTouchdowns</th>\n",
       "      <th>Receptions</th>\n",
       "      <th>ReceivingYards</th>\n",
       "      <th>...</th>\n",
       "      <th>Opponent_TB</th>\n",
       "      <th>Opponent_TEN</th>\n",
       "      <th>Opponent_WAS</th>\n",
       "      <th>Position_FB</th>\n",
       "      <th>Position_QB</th>\n",
       "      <th>Position_RB</th>\n",
       "      <th>Position_TE</th>\n",
       "      <th>Position_WR</th>\n",
       "      <th>Predicted_FP</th>\n",
       "      <th>FantasyPoints</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-11-29</th>\n",
       "      <td>181.0</td>\n",
       "      <td>Todd Gurley</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.234093</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-18</th>\n",
       "      <td>88.0</td>\n",
       "      <td>Mark Ingram</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.066443</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-20</th>\n",
       "      <td>70.0</td>\n",
       "      <td>Rob Gronkowski</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.504550</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-30</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Cole Beasley</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.592657</td>\n",
       "      <td>15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-25</th>\n",
       "      <td>189.0</td>\n",
       "      <td>Giovani Bernard</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.085174</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rank             Name  Week  PassingYards  PassingTouchdowns  \\\n",
       "Date                                                                        \n",
       "2015-11-29  181.0      Todd Gurley    12           0.0                0.0   \n",
       "2016-12-18   88.0      Mark Ingram    15           0.0                0.0   \n",
       "2015-12-20   70.0   Rob Gronkowski    15           0.0                0.0   \n",
       "2018-12-30   36.0     Cole Beasley    17           0.0                0.0   \n",
       "2018-11-25  189.0  Giovani Bernard    12           0.0                0.0   \n",
       "\n",
       "            PassingInterceptions  RushingYards  RushingTouchdowns  Receptions  \\\n",
       "Date                                                                            \n",
       "2015-11-29                   0.0          19.0                0.0         1.0   \n",
       "2016-12-18                   0.0          78.0                0.0         2.0   \n",
       "2015-12-20                   0.0           0.0                0.0         5.0   \n",
       "2018-12-30                   0.0           0.0                0.0         6.0   \n",
       "2018-11-25                   0.0          10.0                0.0         1.0   \n",
       "\n",
       "            ReceivingYards  ...  Opponent_TB  Opponent_TEN  Opponent_WAS  \\\n",
       "Date                        ...                                            \n",
       "2015-11-29            11.0  ...          0.0           0.0           0.0   \n",
       "2016-12-18            14.0  ...          0.0           0.0           0.0   \n",
       "2015-12-20            54.0  ...          0.0           1.0           0.0   \n",
       "2018-12-30            94.0  ...          0.0           0.0           0.0   \n",
       "2018-11-25            12.0  ...          0.0           0.0           0.0   \n",
       "\n",
       "            Position_FB  Position_QB  Position_RB  Position_TE  Position_WR  \\\n",
       "Date                                                                          \n",
       "2015-11-29          0.0          0.0          1.0          0.0          0.0   \n",
       "2016-12-18          0.0          0.0          1.0          0.0          0.0   \n",
       "2015-12-20          0.0          0.0          0.0          1.0          0.0   \n",
       "2018-12-30          0.0          0.0          0.0          0.0          1.0   \n",
       "2018-11-25          0.0          0.0          1.0          0.0          0.0   \n",
       "\n",
       "            Predicted_FP  FantasyPoints  \n",
       "Date                                     \n",
       "2015-11-29      3.234093            3.0  \n",
       "2016-12-18      9.066443            9.2  \n",
       "2015-12-20     11.504550           11.4  \n",
       "2018-12-30     15.592657           15.4  \n",
       "2018-11-25      2.085174            2.2  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()  # preview first 5 rows of validation data\n",
    "# Now, predicted fantasy points per week can be visually compared to true values and all other data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  0.16843704556857517\n",
      "RMSE =  0.4104108253550035\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display validation data MSE and RMSE:\n",
    "test_mse = mean_squared_error(preds, y_test)\n",
    "print('MSE = ', test_mse)\n",
    "print('RMSE = ', np.sqrt(test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  0.03912279946402182\n",
      "RMSE =  0.19779484185393162\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display training data MSE and RMSE:\n",
    "train_preds = model.predict(X_train_sc)\n",
    "train_mse = mean_squared_error(train_preds, y_train)\n",
    "print('MSE = ', train_mse)\n",
    "print('RMSE = ', np.sqrt(train_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
